import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import folium
from streamlit_folium import st_folium
# W03_env\Scripts\activate.bat ì‹œì‘í•  ë•Œ í„°ë¯¸ë„ì— ì¹˜ê¸° 

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans


# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(
    page_title="ì„œìš¸ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë¶„ì„",
    layout="wide"
)

st.title("ì„œìš¸ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ë¦¬ë¹Œë”© Ver.)")

st.caption("""
- í˜ì´ì§€ êµ¬ì¡°: **ì„œìš¸ ì „ì²´ ìš”ì•½ â†’ êµ¬ë³„ ë¶„ì„ â†’ ì´ìƒ ê±°ë˜ íƒìƒ‰ â†’ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„**  
- ì›”ì„¸ ê´€ë ¨ ë¶„ì„ì€ **ì›”ì„¸ê¸ˆ(ë§Œì›) > 0ì¸ ê±°ë˜(ì‹¤ì œ ì›”ì„¸)**ë§Œ ì‚¬ìš©í•˜ê³ ,  
  ì›”ì„¸ 0ì›ì¸ ì „ì„¸ ê±°ë˜ëŠ” **ì „ì„¸ ì „ìš© í†µê³„**ì—ë§Œ í¬í•¨ë©ë‹ˆë‹¤.
""")


# =========================
# 1. ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬
# =========================
@st.cache_data
def load_data():
    # CSV ê²½ë¡œ: data01.pyì™€ ê°™ì€ í´ë”ì— ìˆìœ¼ë©´ íŒŒì¼ëª…ë§Œ ì“°ë©´ ë¨
    # csv_path = "ì˜¤í”¼ìŠ¤í…”(ì „ì›”ì„¸)_ì‹¤ê±°ë˜ê°€_20251119142716.csv"
    csv_path = "ì˜¤í”¼ìŠ¤í…”(ì „ì›”ì„¸)_ì‹¤ê±°ë˜ê°€_20251119142716.csv"

    raw = pd.read_csv(csv_path, encoding="cp949", skiprows=7)

    # ì²« í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ
    header = raw.iloc[0]
    df = raw[1:].copy()
    df.columns = header

    # ìˆ«ìí˜• ì»¬ëŸ¼ ì²˜ë¦¬
    money_cols = ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"]
    for col in money_cols:
        if col in df.columns:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(",", "", regex=False)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")

    num_cols = ["ê³„ì•½ë…„ì›”", "ê³„ì•½ì¼", "ì¸µ", "ê±´ì¶•ë…„ë„"]
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    if "ì „ìš©ë©´ì (ã¡)" in df.columns:
        df["ì „ìš©ë©´ì (ã¡)"] = pd.to_numeric(df["ì „ìš©ë©´ì (ã¡)"], errors="coerce")

    # ------------------------
    # ì‹œêµ°êµ¬ â†’ ì‹œë„ / êµ¬ / ë™ ë¶„ë¦¬
    # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ë…¼í˜„ë™"
    # ------------------------
    if "ì‹œêµ°êµ¬" in df.columns:
        loc = df["ì‹œêµ°êµ¬"].astype(str).str.split()
        df["ì‹œë„"] = loc.str[0]
        df["êµ¬"] = loc.str[1]
        # ë™ì´ ì—†ëŠ” ê²½ìš°ë„ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ì˜ˆì™¸ì ìœ¼ë¡œ NaN ë  ìˆ˜ ìˆìŒ
        df["ë™"] = loc.str[2]

    # ì „ìš©ë©´ì ë‹¹ ì›”ì„¸: ì›”ì„¸ê°€ ìˆëŠ” ê±°ë˜ë§Œ
    if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(df.columns):
        df["ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)"] = np.where(
            (df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0) & (df["ì „ìš©ë©´ì (ã¡)"] > 0),
            df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / df["ì „ìš©ë©´ì (ã¡)"],
            np.nan
        )

    # ì›”ì„¸/ì „ì„¸ êµ¬ë¶„ìš© í”Œë˜ê·¸
    if "ì›”ì„¸ê¸ˆ(ë§Œì›)" in df.columns:
        df["ì›”ì„¸ê³„ì•½ì—¬ë¶€"] = df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0

    return df


df = load_data()

# ì „ì²´ êµ¬ ë¦¬ìŠ¤íŠ¸
all_gu = sorted(df["êµ¬"].dropna().unique())


# =========================
# 2. ì‚¬ì´ë“œë°” ì„¤ì • (í˜ì´ì§€ & í•„í„°)
# =========================
st.sidebar.title("ì„¤ì •")

selected_gu = None
selected_dong = "ì „ì²´"

# â‘  ê¸°ë³¸ ì„ íƒ
with st.sidebar.expander("â‘  ê¸°ë³¸ ì„ íƒ", expanded=True):
    page = st.radio(
        "í˜ì´ì§€ ì„ íƒ",
        ["ì„œìš¸ ì „ì²´ ìš”ì•½", "êµ¬ë³„ ë¶„ì„", "ì´ìƒ ê±°ë˜ íƒìƒ‰", "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„", "ìš”ì¸ ë¶„ì„"]
    )

    if page != "ì„œìš¸ ì „ì²´ ìš”ì•½":
        # ê¸°ë³¸ê°’: ê°•ë‚¨êµ¬ ìˆìœ¼ë©´ ê°•ë‚¨êµ¬, ì•„ë‹ˆë©´ ì²« ë²ˆì§¸
        default_gu = "ê°•ë‚¨êµ¬" if "ê°•ë‚¨êµ¬" in all_gu else all_gu[0]
        selected_gu = st.selectbox(
            "êµ¬ ì„ íƒ",
            options=all_gu,
            index=all_gu.index(default_gu)
        )

        # ì„ íƒëœ êµ¬ ì•ˆì—ì„œ ë™ ëª©ë¡
        dongs_in_gu = sorted(
            df[df["êµ¬"] == selected_gu]["ë™"].dropna().unique()
        )
        selected_dong = st.selectbox(
            "ë™ ì„ íƒ (ì „ì²´ ë³´ë ¤ë©´ 'ì „ì²´')",
            options=["ì „ì²´"] + dongs_in_gu,
            index=0
        )

# â‘¡ ì„¸ë¶€ í•„í„°
with st.sidebar.expander("â‘¡ ì„¸ë¶€ í•„í„°", expanded=(page != "ì„œìš¸ ì „ì²´ ìš”ì•½")):
    # ì „ì›”ì„¸ êµ¬ë¶„
    all_type = sorted(df["ì „ì›”ì„¸êµ¬ë¶„"].dropna().unique())
    if page in ["êµ¬ë³„ ë¶„ì„", "ìš”ì¸ ë¶„ì„"]:
        selected_type = st.multiselect(
            "ì „ì›”ì„¸ êµ¬ë¶„",
            options=all_type,
            default=all_type
        )
    else:
        # ì´ìƒ íƒì§€ / í´ëŸ¬ìŠ¤í„°ë§ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì›”ì„¸ ìœ„ì£¼
        default_type = [t for t in all_type if "ì›”ì„¸" in t] or all_type
        selected_type = st.multiselect(
            "ì „ì›”ì„¸ êµ¬ë¶„",
            options=all_type,
            default=default_type
        )

    # ì „ìš©ë©´ì 
    if "ì „ìš©ë©´ì (ã¡)" in df.columns:
        min_area = float(np.nanmin(df["ì „ìš©ë©´ì (ã¡)"]))
        max_area = float(np.nanmax(df["ì „ìš©ë©´ì (ã¡)"]))
        area_range = st.slider(
            "ì „ìš©ë©´ì  ë²”ìœ„ (ã¡)",
            min_value=float(round(min_area, 1)),
            max_value=float(round(max_area, 1)),
            value=(float(round(min_area, 1)), float(round(max_area, 1)))
        )
    else:
        area_range = None

    # ê±´ì¶•ë…„ë„
    if "ê±´ì¶•ë…„ë„" in df.columns:
        min_year = int(np.nanmin(df["ê±´ì¶•ë…„ë„"]))
        max_year = int(np.nanmax(df["ê±´ì¶•ë…„ë„"]))
        year_range = st.slider(
            "ê±´ì¶•ë…„ë„ ë²”ìœ„",
            min_value=min_year,
            max_value=max_year,
            value=(min_year, max_year)
        )
    else:
        year_range = None

    only_renew = st.checkbox("ê°±ì‹  ê³„ì•½ë§Œ ë³´ê¸° (ê³„ì•½êµ¬ë¶„ == 'ê°±ì‹ ')", value=False)

# â‘¢ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
with st.sidebar.expander("â‘¢ ë‹¤ìš´ë¡œë“œ", expanded=False):
    st.caption("ê° í˜ì´ì§€ í•˜ë‹¨ì—ì„œ **í•„í„° ì ìš© ë°ì´í„° / ì´ìƒ ê±°ë˜ / í´ëŸ¬ìŠ¤í„° ê²°ê³¼**ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# 3. ê³µí†µ í•„í„° í•¨ìˆ˜ (êµ¬ + ë™)
# =========================
def apply_common_filters(df_in, gu=None, dong="ì „ì²´"):
    df_out = df_in.copy()

    if gu is not None:
        df_out = df_out[df_out["êµ¬"] == gu]

    if dong != "ì „ì²´":
        df_out = df_out[df_out["ë™"] == dong]

    if selected_type:
        df_out = df_out[df_out["ì „ì›”ì„¸êµ¬ë¶„"].isin(selected_type)]

    if area_range is not None and "ì „ìš©ë©´ì (ã¡)" in df_out.columns:
        df_out = df_out[
            (df_out["ì „ìš©ë©´ì (ã¡)"] >= area_range[0]) &
            (df_out["ì „ìš©ë©´ì (ã¡)"] <= area_range[1])
        ]

    if year_range is not None and "ê±´ì¶•ë…„ë„" in df_out.columns:
        df_out = df_out[
            (df_out["ê±´ì¶•ë…„ë„"] >= year_range[0]) &
            (df_out["ê±´ì¶•ë…„ë„"] <= year_range[1])
        ]

    if only_renew and "ê³„ì•½êµ¬ë¶„" in df_out.columns:
        df_out = df_out[df_out["ê³„ì•½êµ¬ë¶„"] == "ê°±ì‹ "]

    return df_out


# =========================
# 4. í˜ì´ì§€ 1: ì„œìš¸ ì „ì²´ ìš”ì•½
# =========================
if page == "ì„œìš¸ ì „ì²´ ìš”ì•½":
    st.header("ğŸ“ ì„œìš¸ ì „ì²´ ìš”ì•½")

    st.write("#### ğŸ” ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ")
    st.dataframe(df.head())

    st.write("---")
    st.subheader("ğŸ™ï¸ êµ¬ë³„ ì „ì›”ì„¸ ê±°ë˜ ìš”ì•½")

    # ì›”ì„¸ ê±°ë˜ë§Œ ë³„ë„
    df_rent = df[df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]
    df_jeonse = df[df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] == 0]

    summary = (
        df.groupby("êµ¬")
        .agg(
            ì „ì²´ê±°ë˜ìˆ˜=("NO", "count"),
            í‰ê· ë³´ì¦ê¸ˆ=("ë³´ì¦ê¸ˆ(ë§Œì›)", "mean")
        )
        .reset_index()
    )

    rent_summary = (
        df_rent.groupby("êµ¬")
        .agg(
            ì›”ì„¸ê³„ì•½ìˆ˜=("NO", "count"),
            í‰ê· ì›”ì„¸=("ì›”ì„¸ê¸ˆ(ë§Œì›)", "mean")
        )
        .reset_index()
    )

    merged = pd.merge(summary, rent_summary, on="êµ¬", how="left")

    st.dataframe(merged)

    st.download_button(
        "êµ¬ë³„ ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
        merged.to_csv(index=False).encode("utf-8-sig"),
        file_name="ì„œìš¸_êµ¬ë³„_ìš”ì•½.csv"
    )

    st.write("#### ğŸ“Š êµ¬ë³„ í‰ê·  ì›”ì„¸ (ì›”ì„¸ ê±°ë˜ë§Œ)")

    if len(df_rent) > 0:
        avg_rent_by_gu = (
            df_rent.groupby("êµ¬")["ì›”ì„¸ê¸ˆ(ë§Œì›)"]
            .mean()
            .reset_index()
        )

        chart = (
            alt.Chart(avg_rent_by_gu)
            .mark_bar()
            .encode(
                x=alt.X("êµ¬:N", sort="-y", title="êµ¬"),
                y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="í‰ê·  ì›”ì„¸ (ë§Œì›)"),
                tooltip=["êµ¬", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]
            )
        )
        st.altair_chart(chart, use_container_width=True)
    else:
        st.info("ì›”ì„¸ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.write("#### ğŸ¢ ì „ì„¸(ì›”ì„¸ 0ì›) ê±°ë˜ ë¹„ì¤‘")
    jeonse_ratio = len(df_jeonse) / len(df) * 100 if len(df) > 0 else 0
    st.metric("ì „ì„¸(ì›”ì„¸ 0ì›) ë¹„ì¤‘", f"{jeonse_ratio:,.1f}%")

    st.write("---")
    st.caption("â€» ë‹¤ë¥¸ í˜ì´ì§€ì—ì„œ êµ¬ì™€ ë™ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ êµ¬Â·ë™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìì„¸í•œ ë¶„ì„ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# 5. í˜ì´ì§€ 2: êµ¬ë³„ ë¶„ì„ (êµ¬ + ë™)
# =========================
elif page == "êµ¬ë³„ ë¶„ì„":
    title_suffix = "" if selected_dong == "ì „ì²´" else f" ({selected_dong})"
    st.header(f"ğŸ™ï¸ {selected_gu}{title_suffix} ìƒì„¸ ë¶„ì„")

    filtered = apply_common_filters(df, gu=selected_gu, dong=selected_dong)

    if len(filtered) == 0:
        st.info("í˜„ì¬ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì¡°ê±´ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
    else:
        # ì›”ì„¸ / ì „ì„¸ ë‚˜ëˆ„ê¸°
        rent_df = filtered[filtered["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]
        jeonse_df = filtered[filtered["ì›”ì„¸ê¸ˆ(ë§Œì›)"] == 0]

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì „ì²´ ê±°ë˜ ê±´ìˆ˜", f"{len(filtered):,} ê±´")
        with col2:
            st.metric("ì›”ì„¸ ê±°ë˜ ìˆ˜", f"{len(rent_df):,} ê±´")
        with col3:
            st.metric("ì „ì„¸(ì›”ì„¸ 0) ê±°ë˜ ìˆ˜", f"{len(jeonse_df):,} ê±´")
        with col4:
            avg_deposit = filtered["ë³´ì¦ê¸ˆ(ë§Œì›)"].mean()
            st.metric("í‰ê·  ë³´ì¦ê¸ˆ (ë§Œì›)", f"{avg_deposit:,.0f}")

        st.write("---")
        st.subheader("ğŸ’° ì›”ì„¸ ê±°ë˜ ë¶„í¬ (ì›”ì„¸ > 0ì¸ ê±°ë˜ë§Œ)")

        if len(rent_df) > 0:
            # ì›”ì„¸ íˆìŠ¤í† ê·¸ë¨
            rent_hist = (
                alt.Chart(rent_df)
                .mark_bar()
                .encode(
                    x=alt.X("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", bin=alt.Bin(maxbins=30), title="ì›”ì„¸ (ë§Œì›)"),
                    y=alt.Y("count():Q", title="ê±°ë˜ ê±´ìˆ˜"),
                    tooltip=["count()"]
                )
            )
            st.altair_chart(rent_hist, use_container_width=True)

            # ì „ìš©ë©´ì  vs ì›”ì„¸ ì‚°ì ë„
            if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(rent_df.columns):
                scatter = (
                    alt.Chart(rent_df)
                    .mark_circle(size=60, opacity=0.6)
                    .encode(
                        x=alt.X("ì „ìš©ë©´ì (ã¡):Q"),
                        y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q"),
                        tooltip=[
                            "êµ¬", "ë™",
                            "ë‹¨ì§€ëª…",
                            "ì „ì›”ì„¸êµ¬ë¶„",
                            "ì „ìš©ë©´ì (ã¡)",
                            "ë³´ì¦ê¸ˆ(ë§Œì›)",
                            "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                            "ì¸µ",
                            "ê±´ì¶•ë…„ë„",
                            "ê³„ì•½ë…„ì›”"
                        ]
                    )
                )
                st.write("#### ğŸ“ˆ ì „ìš©ë©´ì  vs ì›”ì„¸ (ì›”ì„¸ ê±°ë˜ë§Œ)")
                st.altair_chart(scatter, use_container_width=True)
        else:
            st.info("ì›”ì„¸ ê±°ë˜ê°€ ì—†ì–´ ì›”ì„¸ ë¶„í¬ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.write("#### ğŸ“‹ í•„í„° ì ìš©ëœ ìƒì„¸ ë°ì´í„°")
        st.dataframe(filtered)

        st.download_button(
            f"{selected_gu}_{selected_dong}_í•„í„°_ì ìš©_ë°ì´í„°.csv ë‹¤ìš´ë¡œë“œ",
            filtered.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{selected_gu}_{selected_dong}_í•„í„°_ë°ì´í„°.csv"
        )


# =========================
# 6. í˜ì´ì§€ 3: ì´ìƒ ê±°ë˜ íƒìƒ‰ (êµ¬ + ë™)
# =========================
elif page == "ì´ìƒ ê±°ë˜ íƒìƒ‰":
    title_suffix = "" if selected_dong == "ì „ì²´" else f" ({selected_dong})"
    st.header(f"âš  ì´ìƒ ê±°ë˜ íƒìƒ‰ â€“ {selected_gu}{title_suffix}")

    base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)
    rent_base = base[base["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]  # ì›”ì„¸ ê±°ë˜ë§Œ

    st.caption("â€» ì›”ì„¸ ê´€ë ¨ ê¸°ì¤€ì€ **ì›”ì„¸ê¸ˆ(ë§Œì›) > 0**ì¸ ê±°ë˜ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì „ì„¸ëŠ” ì œì™¸)")

    if len(base) == 0 or len(rent_base) == 0:
        st.info("í˜„ì¬ í•„í„°ì—ì„œ ë¶„ì„ ê°€ëŠ¥í•œ ì›”ì„¸ ê±°ë˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        tab1, tab2, tab3 = st.tabs([
            "â‘  ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨",
            "â‘¡ ê°±ì‹  ì‹œ ì¸ìƒë¥ ",
            "â‘¢ ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€"
        ])

        # -------------------------
        # TAB 1: ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨
        # -------------------------
        with tab1:
            st.subheader("â‘  ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨ì´ ë†’ì€ ê±°ë˜")

            t1 = rent_base.copy()
            t1 = t1[(t1["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0)].copy()
            t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"] = t1["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / t1["ë³´ì¦ê¸ˆ(ë§Œì›)"]

            if len(t1) == 0:
                st.info("ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ê°€ ëª¨ë‘ ìˆëŠ” ì›”ì„¸ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                top_pct = st.slider(
                    "ìƒìœ„ ëª‡ %ë¥¼ ì´ìƒ ê±°ë˜ë¡œ ë³¼ê¹Œìš”?",
                    min_value=5, max_value=30, value=10, step=1
                )
                threshold = t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"].quantile(1 - top_pct / 100)
                anomalies_t1 = t1[t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"] >= threshold].copy()
                anomalies_t1 = anomalies_t1.sort_values(
                    "ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨", ascending=False
                )

                c1, c2 = st.columns(2)
                with c1:
                    st.metric("ì›”ì„¸ ê±°ë˜ ìˆ˜", f"{len(t1):,} ê±´")
                with c2:
                    st.metric(f"ë¹„ìœ¨ ìƒìœ„ {top_pct}% ê±°ë˜ ìˆ˜", f"{len(anomalies_t1):,} ê±´")

                st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ ë¦¬ìŠ¤íŠ¸")
                show_cols = [
                    "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…", "ì „ì›”ì„¸êµ¬ë¶„", "ì „ìš©ë©´ì (ã¡)",
                    "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨", "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)",
                    "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”", "ê³„ì•½êµ¬ë¶„"
                ]
                show_cols = [c for c in show_cols if c in anomalies_t1.columns]
                st.dataframe(anomalies_t1[show_cols])

                st.download_button(
                    "ì´ìƒ ê±°ë˜(ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨) CSV ë‹¤ìš´ë¡œë“œ",
                    anomalies_t1.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ë¹„ìœ¨ê¸°ì¤€.csv"
                )

        # -------------------------
        # TAB 2: ê°±ì‹  ì‹œ ì¸ìƒë¥ 
        # -------------------------
        with tab2:
            st.subheader("â‘¡ ê°±ì‹  ê³„ì•½ ì¤‘ ì›”ì„¸ ì¸ìƒë¥ ì´ í° ê±°ë˜")

            needed = {"ê³„ì•½êµ¬ë¶„", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"}
            if not needed.issubset(base.columns):
                st.warning("ê°±ì‹  ê³„ì•½ ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                t2 = base.copy()
                t2 = t2[
                    (t2["ê³„ì•½êµ¬ë¶„"] == "ê°±ì‹ ") &
                    (t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"] > 0)
                ].copy()

                if len(t2) == 0:
                    st.info("ê°±ì‹  ê³„ì•½(ì¢…ì „ ì›”ì„¸ ì •ë³´ í¬í•¨)ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    t2["ì›”ì„¸ì¸ìƒë¥ (%)"] = (
                        (t2["ì›”ì„¸ê¸ˆ(ë§Œì›)"] - t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"]) /
                        t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"] * 100
                    )

                    base_pos = t2[t2["ì›”ì„¸ì¸ìƒë¥ (%)"] > 0]

                    if len(base_pos) == 0:
                        st.info("ì›”ì„¸ ì¸ìƒë¥ ì´ ì–‘ìˆ˜ì¸ ê°±ì‹  ê³„ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        top_pct2 = st.slider(
                            "ì›”ì„¸ ì¸ìƒë¥  ìƒìœ„ ëª‡ %ë¥¼ ì´ìƒìœ¼ë¡œ ë³¼ê¹Œìš”?",
                            min_value=5, max_value=30, value=10, step=1
                        )
                        thr2 = base_pos["ì›”ì„¸ì¸ìƒë¥ (%)"].quantile(1 - top_pct2 / 100)
                        anomalies_t2 = base_pos[base_pos["ì›”ì„¸ì¸ìƒë¥ (%)"] >= thr2].copy()
                        anomalies_t2 = anomalies_t2.sort_values(
                            "ì›”ì„¸ì¸ìƒë¥ (%)", ascending=False
                        )

                        c1, c2 = st.columns(2)
                        with c1:
                            st.metric("ê°±ì‹  ê³„ì•½ ìˆ˜", f"{len(base_pos):,} ê±´")
                        with c2:
                            st.metric(
                                f"ì¸ìƒë¥  ìƒìœ„ {top_pct2}% ê±°ë˜ ìˆ˜",
                                f"{len(anomalies_t2):,} ê±´"
                            )

                        show_cols2 = [
                            "êµ¬", "ë™",
                            "ë‹¨ì§€ëª…", "ì „ì›”ì„¸êµ¬ë¶„", "ì „ìš©ë©´ì (ã¡)",
                            "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                            "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)",
                            "ì›”ì„¸ì¸ìƒë¥ (%)",
                            "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”", "ê°±ì‹ ìš”êµ¬ê¶Œ ì‚¬ìš©"
                        ]
                        show_cols2 = [c for c in show_cols2 if c in anomalies_t2.columns]

                        st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ ë¦¬ìŠ¤íŠ¸ (ê°±ì‹  ì¸ìƒë¥ )")
                        st.dataframe(anomalies_t2[show_cols2])

                        st.download_button(
                            "ì´ìƒ ê±°ë˜(ê°±ì‹  ì¸ìƒë¥ ) CSV ë‹¤ìš´ë¡œë“œ",
                            anomalies_t2.to_csv(index=False).encode("utf-8-sig"),
                            file_name=f"{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ê°±ì‹ ì¸ìƒë¥ .csv"
                        )

        # -------------------------
        # TAB 3: ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€
        # -------------------------
        with tab3:
            st.subheader("â‘¢ ë¹„ìŠ·í•œ ë©´ì ëŒ€ ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€ ê±°ë˜")

            t3 = rent_base.dropna(subset=["ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]).copy()

            if len(t3) == 0:
                st.info("ì „ìš©ë©´ì ê³¼ ì›”ì„¸ê°€ ëª¨ë‘ ìˆëŠ” ì›”ì„¸ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                bin_size = st.slider(
                    "ì „ìš©ë©´ì  êµ¬ê°„ í­ (ã¡)",
                    min_value=5, max_value=30, value=10, step=5
                )

                min_area = t3["ì „ìš©ë©´ì (ã¡)"].min()
                max_area = t3["ì „ìš©ë©´ì (ã¡)"].max()

                bins = np.arange(
                    np.floor(min_area),
                    np.ceil(max_area) + bin_size,
                    bin_size
                )
                t3["ë©´ì êµ¬ê°„"] = pd.cut(
                    t3["ì „ìš©ë©´ì (ã¡)"],
                    bins=bins,
                    include_lowest=True
                )

                grp = (
                    t3.groupby("ë©´ì êµ¬ê°„")
                    .agg(ë¡œì»¬í‰ê· ì›”ì„¸=("ì›”ì„¸ê¸ˆ(ë§Œì›)", "mean"))
                    .reset_index()
                )

                t3 = t3.merge(grp, on="ë©´ì êµ¬ê°„", how="left")
                t3["í¸ì°¨(%)"] = (
                    (t3["ì›”ì„¸ê¸ˆ(ë§Œì›)"] - t3["ë¡œì»¬í‰ê· ì›”ì„¸"]) /
                    t3["ë¡œì»¬í‰ê· ì›”ì„¸"] * 100
                )

                cutoff = st.slider(
                    "ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ëª‡ % ì´ìƒì„ ê³ ê°€ë¡œ ë³¼ê¹Œìš”?",
                    min_value=10, max_value=80, value=30, step=5
                )

                anomalies_t3 = t3[t3["í¸ì°¨(%)"] >= cutoff].copy()
                anomalies_t3 = anomalies_t3.sort_values("í¸ì°¨(%)", ascending=False)

                c1, c2 = st.columns(2)
                with c1:
                    st.metric("ë¹„êµ ëŒ€ìƒ ê±°ë˜ ìˆ˜", f"{len(t3):,} ê±´")
                with c2:
                    st.metric(
                        f"ë¡œì»¬ í‰ê·  ëŒ€ë¹„ {cutoff}% ì´ìƒ ê³ ê°€ ê±°ë˜ ìˆ˜",
                        f"{len(anomalies_t3):,} ê±´"
                    )

                st.write("#### ğŸ“‹ ê³ ê°€ ê±°ë˜ ë¦¬ìŠ¤íŠ¸")
                show_cols3 = [
                    "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…", "ì „ì›”ì„¸êµ¬ë¶„", "ë©´ì êµ¬ê°„",
                    "ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë¡œì»¬í‰ê· ì›”ì„¸", "í¸ì°¨(%)",
                    "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”"
                ]
                show_cols3 = [c for c in show_cols3 if c in anomalies_t3.columns]
                st.dataframe(anomalies_t3[show_cols3])

                st.download_button(
                    "ì´ìƒ ê±°ë˜(ë¡œì»¬ ê³ ê°€) CSV ë‹¤ìš´ë¡œë“œ",
                    anomalies_t3.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ë¡œì»¬ê³ ê°€.csv"
                )
                st.write("#### ğŸ—º ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€ ê±°ë˜ ì§€ë„(êµ¬ ì¤‘ì‹¬ ì¢Œí‘œ ê¸°ë°˜)")

                # ì„œìš¸ ê° êµ¬ì˜ ëŒ€ëµì ì¸ ì¤‘ì‹¬ ì¢Œí‘œ (ìœ„ë„, ê²½ë„)
                seoul_gu_coords = {
                    "ê°•ë‚¨êµ¬": (37.5172, 127.0473),
                    "ì„œì´ˆêµ¬": (37.4836, 127.0327),
                    "ì†¡íŒŒêµ¬": (37.5145, 127.1066),
                    "ìš©ì‚°êµ¬": (37.5311, 126.9810),
                    "ì¤‘êµ¬": (37.5636, 126.9976),
                    "ì¢…ë¡œêµ¬": (37.5730, 126.9794),
                    "ë§ˆí¬êµ¬": (37.5663, 126.9014),
                    "ì˜ë“±í¬êµ¬": (37.5263, 126.8962),
                    "ì–‘ì²œêµ¬": (37.5169, 126.8665),
                    "ê°•ì„œêµ¬": (37.5509, 126.8495),
                    "êµ¬ë¡œêµ¬": (37.4954, 126.8874),
                    "ê¸ˆì²œêµ¬": (37.4569, 126.8959),
                    "ê´€ì•…êµ¬": (37.4784, 126.9516),
                    "ë™ì‘êµ¬": (37.5124, 126.9393),
                    "ë™ëŒ€ë¬¸êµ¬": (37.5740, 127.0396),
                    "ì„±ë™êµ¬": (37.5634, 127.0369),
                    "ê´‘ì§„êµ¬": (37.5384, 127.0823),
                    "ì„±ë¶êµ¬": (37.5894, 127.0167),
                    "ê°•ë¶êµ¬": (37.6396, 127.0257),
                    "ë„ë´‰êµ¬": (37.6688, 127.0471),
                    "ë…¸ì›êµ¬": (37.6543, 127.0565),
                    "ì¤‘ë‘êµ¬": (37.6063, 127.0928),
                    "ì„œëŒ€ë¬¸êµ¬": (37.5791, 126.9368),
                    "ì€í‰êµ¬": (37.6176, 126.9227),
                    "ê°•ë™êµ¬": (37.5301, 127.1238),
                }

                # êµ¬ë³„ ê³ ê°€ ê±°ë˜ ë¹„ìœ¨ ê³„ì‚° (í˜„ì¬ í•„í„° ë‚´ì—ì„œ)
                if len(t3) > 0:
                    gu_counts = t3["êµ¬"].value_counts().rename("ì „ì²´ê±°ë˜ìˆ˜")
                    gu_anom_counts = anomalies_t3["êµ¬"].value_counts().rename("ê³ ê°€ê±°ë˜ìˆ˜")

                    gu_ratio = (
                        pd.concat([gu_counts, gu_anom_counts], axis=1)
                        .fillna(0)
                        .reset_index()
                        .rename(columns={"index": "êµ¬"})
                    )
                    gu_ratio["ê³ ê°€ë¹„ìœ¨(%)"] = (
                        gu_ratio["ê³ ê°€ê±°ë˜ìˆ˜"] / gu_ratio["ì „ì²´ê±°ë˜ìˆ˜"] * 100
                    )

                    # ì§€ë„ ì¤‘ì‹¬ì€ ì„ íƒëœ êµ¬ê°€ ìˆìœ¼ë©´ ê·¸ìª½, ì—†ìœ¼ë©´ ì„œìš¸ ì‹œì²­ ê·¼ì²˜
                    if selected_gu in seoul_gu_coords:
                        center_lat, center_lng = seoul_gu_coords[selected_gu]
                    else:
                        center_lat, center_lng = 37.5665, 126.9780  # ì„œìš¸ ì‹œì²­ ê·¼ë°©

                    m = folium.Map(location=[center_lat, center_lng], zoom_start=11)

                    # êµ¬ë³„ë¡œ ì›(circle) í‘œì‹œ
                    for _, row in gu_ratio.iterrows():
                        gu_name = row["êµ¬"]
                        if gu_name not in seoul_gu_coords:
                            continue

                        lat, lng = seoul_gu_coords[gu_name]
                        ratio = row["ê³ ê°€ë¹„ìœ¨(%)"]

                        # ë¹„ìœ¨ì— ë”°ë¼ ì› í¬ê¸° ì¡°ì ˆ (ê¸°ë³¸ 200 + ê°€ì¤‘)
                        radius = 200 + ratio * 10

                        popup_text = (
                            f"{gu_name}<br>"
                            f"ê³ ê°€ ê±°ë˜ìˆ˜: {int(row['ê³ ê°€ê±°ë˜ìˆ˜'])}ê±´<br>"
                            f"ì „ì²´ ê±°ë˜ìˆ˜: {int(row['ì „ì²´ê±°ë˜ìˆ˜'])}ê±´<br>"
                            f"ê³ ê°€ ë¹„ìœ¨: {ratio:.1f}%"
                        )

                        folium.Circle(
                            location=[lat, lng],
                            radius=radius,
                            popup=popup_text,
                            color="red",
                            fill=True,
                            fill_opacity=0.5,
                        ).add_to(m)

                    st_folium(m, width=700, height=500)
                else:
                    st.info("ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ë¹„êµ ëŒ€ìƒ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# =========================
# 7. í˜ì´ì§€ 4: ìš”ì¸ ë¶„ì„ (ë‹¤ì¤‘ìš”ì¸ ì˜í–¥)
# =========================
elif page == "ìš”ì¸ ë¶„ì„":
    title_suffix = "" if selected_dong == "ì „ì²´" else f" ({selected_dong})"
    st.header(f"ğŸ“Š ìš”ì¸ë³„ ì„ëŒ€ë£Œ ì˜í–¥ ë¶„ì„ â€“ {selected_gu}{title_suffix}")

    base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)

    st.caption("â€» í˜„ì¬ ì„ íƒëœ êµ¬/ë™ ë° í•„í„°(ì „ì›”ì„¸, ë©´ì , ê±´ì¶•ë…„ë„, ê°±ì‹  ì—¬ë¶€)ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    if len(base) < 30:
        st.info("ìš”ì¸ ë¶„ì„ì„ ì§„í–‰í•˜ê¸°ì— ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        tab_corr, tab_reg = st.tabs(["ìƒê´€ ë¶„ì„", "íšŒê·€ ë¶„ì„"])

        # -------------------------
        # TAB 1: ìƒê´€ ë¶„ì„
        # -------------------------
        with tab_corr:
            st.subheader("â‘  ì£¼ìš” ìˆ˜ì¹˜ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„")

            corr_cols = [
                "ì „ìš©ë©´ì (ã¡)",
                "ë³´ì¦ê¸ˆ(ë§Œì›)",
                "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)",
                "ì¸µ",
                "ê±´ì¶•ë…„ë„",
            ]

            use_cols = [c for c in corr_cols if c in base.columns]
            data_corr = base[use_cols].dropna()

            if data_corr.shape[0] < 10:
                st.info("ìƒê´€ ë¶„ì„ì„ ìœ„í•œ ìœ íš¨í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                corr = data_corr.corr()

                st.write("##### ìƒê´€ê³„ìˆ˜ í‘œ")
                st.dataframe(corr.style.background_gradient(cmap="RdBu_r"))

                st.write("##### ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ")

                corr_reset = corr.reset_index()
                first_col = corr_reset.columns[0]

                corr_melt = (
                    corr_reset
                    .rename(columns={first_col: "ë³€ìˆ˜1"})
                    .melt("ë³€ìˆ˜1", var_name="ë³€ìˆ˜2", value_name="ìƒê´€ê³„ìˆ˜")
                )

                heatmap = (
                    alt.Chart(corr_melt)
                    .mark_rect()
                    .encode(
                        x=alt.X("ë³€ìˆ˜1:N", title=""),
                        y=alt.Y("ë³€ìˆ˜2:N", title=""),
                        color=alt.Color("ìƒê´€ê³„ìˆ˜:Q", scale=alt.Scale(scheme="redblue")),
                        tooltip=["ë³€ìˆ˜1", "ë³€ìˆ˜2", "ìƒê´€ê³„ìˆ˜"]
                    )
                )

                text = (
                    alt.Chart(corr_melt)
                    .mark_text(baseline="middle")
                    .encode(
                        x="ë³€ìˆ˜1:N",
                        y="ë³€ìˆ˜2:N",
                        text=alt.Text("ìƒê´€ê³„ìˆ˜:Q", format=".2f")
                    )
                )

                st.altair_chart(heatmap + text, use_container_width=True)

        # -------------------------
        # TAB 2: íšŒê·€ ë¶„ì„
        # -------------------------
        with tab_reg:
            st.subheader("â‘¡ ë‹¤ì¤‘ íšŒê·€ ë¶„ì„")

            target = st.radio(
                "ì¢…ì† ë³€ìˆ˜(ì„¤ëª…í•˜ê³  ì‹¶ì€ ì„ëŒ€ë£Œ)ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                ["ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë³´ì¦ê¸ˆ(ë§Œì›)"],
                index=0
            )

            data_reg = base.copy()

            # ì¢…ì† ë³€ìˆ˜ì— ë§ê²Œ ê±°ë˜ í•„í„°ë§
            if target == "ì›”ì„¸ê¸ˆ(ë§Œì›)":
                data_reg = data_reg[data_reg["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]
            else:
                data_reg = data_reg[data_reg["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0]

            # ì‚¬ìš©í•  ì„¤ëª… ë³€ìˆ˜ë“¤
            num_features = []
            for col in ["ì „ìš©ë©´ì (ã¡)", "ì¸µ", "ê±´ì¶•ë…„ë„", "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)"]:
                if col in data_reg.columns:
                    num_features.append(col)

            cat_features = []
            for col in ["êµ¬", "ê³„ì•½êµ¬ë¶„", "ì „ì›”ì„¸êµ¬ë¶„"]:
                if col in data_reg.columns:
                    cat_features.append(col)

            if target not in data_reg.columns or len(num_features) == 0:
                st.info("íšŒê·€ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                # X, y êµ¬ì„±
                X = data_reg[num_features + cat_features].copy()
                y = data_reg[target].copy()

                # ì›-í•« ì¸ì½”ë”©
                if cat_features:
                    X = pd.get_dummies(X, columns=cat_features, drop_first=True)

                # ê²°ì¸¡ì¹˜ ì œê±°
                reg_df = pd.concat([X, y], axis=1).dropna()
                X = reg_df[X.columns]
                y = reg_df[target]

                if X.shape[0] < 50 or X.shape[1] == 0:
                    st.info("íšŒê·€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸°ì— ìœ íš¨í•œ ë°ì´í„°(í‘œë³¸ ìˆ˜)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    model = LinearRegression()
                    model.fit(X, y)

                    r2 = model.score(X, y)

                    st.write("##### ëª¨ë¸ ìš”ì•½")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("í‘œë³¸ ìˆ˜", f"{X.shape[0]:,} ê±´")
                    with col2:
                        st.metric("ê²°ì •ê³„ìˆ˜ (RÂ²)", f"{r2:.3f}")

                    coef_series = pd.Series(model.coef_, index=X.columns)
                    coef_df = (
                        pd.DataFrame({
                            "ë³€ìˆ˜": coef_series.index,
                            "íšŒê·€ê³„ìˆ˜": coef_series.values,
                            "ì ˆëŒ€ê°’": coef_series.abs().values
                        })
                        .sort_values("ì ˆëŒ€ê°’", ascending=False)
                    )[["ë³€ìˆ˜", "íšŒê·€ê³„ìˆ˜"]]

                    st.write("##### ë³€ìˆ˜ë³„ ì˜í–¥ë ¥ (ê³„ìˆ˜ í¬ê¸° ê¸°ì¤€ ì •ë ¬)")
                    st.dataframe(coef_df)

                    st.caption("""
- íšŒê·€ê³„ìˆ˜ê°€ ì–‘ìˆ˜ì´ë©´, í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ì„ëŒ€ë£Œê°€ ì¦ê°€í•˜ëŠ” ë°©í–¥ì…ë‹ˆë‹¤.  
- ìŒìˆ˜ì´ë©´, í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ì„ëŒ€ë£Œê°€ ê°ì†Œí•˜ëŠ” ë°©í–¥ì…ë‹ˆë‹¤.  
- RÂ² ê°’ì€ ì´ ëª¨ë¸ì´ ì„ëŒ€ë£Œ ë³€ë™ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
""")


# =========================
# 8. í˜ì´ì§€ 4: í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ (êµ¬ + ë™)
# =========================
elif page == "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„":
    title_suffix = "" if selected_dong == "ì „ì²´" else f" ({selected_dong})"
    st.header(f"ğŸ” í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ â€“ {selected_gu}{title_suffix}")

    base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)
    rent_base = base[base["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]  # ì›”ì„¸ ê±°ë˜ë§Œ

    if len(rent_base) < 10:
        st.info("í´ëŸ¬ìŠ¤í„°ë§ì„ í•˜ê¸°ì—ëŠ” ì›”ì„¸ ê±°ë˜ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        tab_k1, tab_k2 = st.tabs(["ì „ì²´ ì›”ì„¸ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§", "ì´ìƒ ê±°ë˜ ì¤‘ì‹¬ í´ëŸ¬ìŠ¤í„°ë§"])

        # -------------------------
        # TAB K1: ì „ì²´ ì›”ì„¸ ê±°ë˜
        # -------------------------
        with tab_k1:
            st.subheader("â‘  ì „ì²´ ì›”ì„¸ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§")

            use_cols = [
                "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)", "ê±´ì¶•ë…„ë„", "ì¸µ"
            ]
            use_cols = [c for c in use_cols if c in rent_base.columns]

            data_k = rent_base[use_cols].dropna().copy()

            if len(data_k) < 10:
                st.info("ìœ íš¨í•œ ë°ì´í„°(ê²°ì¸¡ê°’ ì œê±° í›„)ê°€ ë¶€ì¡±í•´ í´ëŸ¬ìŠ¤í„°ë§ì´ ì–´ë µìŠµë‹ˆë‹¤.")
            else:
                k = st.slider("í´ëŸ¬ìŠ¤í„° ìˆ˜ (K)", min_value=2, max_value=8, value=4)

                scaler = StandardScaler()
                scaled = scaler.fit_transform(data_k)

                model = KMeans(n_clusters=k, random_state=42, n_init="auto")
                labels = model.fit_predict(scaled)

                data_k["cluster"] = labels
                data_k["cluster"] = data_k["cluster"].astype(int)

                # ì›ë³¸ ì¸ë±ìŠ¤ë¡œë¶€í„° ë‹¨ì§€ëª… ë“± ë¶™ì´ê¸°
                result = data_k.merge(
                    rent_base[["êµ¬", "ë™", "ë‹¨ì§€ëª…", "ê³„ì•½ë…„ì›”", "ì „ì›”ì„¸êµ¬ë¶„"]],
                    left_index=True,
                    right_index=True,
                    how="left"
                )

                st.write("#### ğŸ“‹ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìƒ˜í”Œ")
                st.dataframe(result.head(50))

                st.download_button(
                    "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    result.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_gu}_{selected_dong}_í´ëŸ¬ìŠ¤í„°ë§_ì „ì²´ì›”ì„¸.csv"
                )

                st.write("#### ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’")
                summary_k = data_k.groupby("cluster").mean()
                st.dataframe(summary_k)

                if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(data_k.columns):
                    chart_df = data_k.reset_index(drop=True).copy()
                    chart_df["cluster"] = chart_df["cluster"].astype(str)

                    scatter = (
                        alt.Chart(chart_df)
                        .mark_circle(size=60, opacity=0.6)
                        .encode(
                            x="ì „ìš©ë©´ì (ã¡):Q",
                            y="ì›”ì„¸ê¸ˆ(ë§Œì›):Q",
                            color="cluster:N",
                            tooltip=["cluster", "ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë³´ì¦ê¸ˆ(ë§Œì›)"]
                        )
                    )
                    st.write("#### ğŸ¨ ì „ìš©ë©´ì  vs ì›”ì„¸ (í´ëŸ¬ìŠ¤í„° ìƒ‰)")
                    st.altair_chart(scatter, use_container_width=True)

        # -------------------------
        # TAB K2: ì´ìƒ ê±°ë˜ ì¤‘ì‹¬
        # -------------------------
        with tab_k2:
            st.subheader("â‘¡ ì´ìƒ ê±°ë˜ ì¤‘ì‹¬ í´ëŸ¬ìŠ¤í„°ë§")

            df_anom = rent_base.copy()

            # ê°„ë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì´ìƒ í”Œë˜ê·¸ (ìƒìœ„ 10%ì”©)
            # 1) ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨
            df_anom["ë¹„ìœ¨"] = np.where(
                df_anom["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0,
                df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / df_anom["ë³´ì¦ê¸ˆ(ë§Œì›)"],
                np.nan
            )
            thr1 = df_anom["ë¹„ìœ¨"].quantile(0.90)
            df_anom["ì´ìƒ_ë¹„ìœ¨"] = df_anom["ë¹„ìœ¨"] >= thr1

            # 2) ì›”ì„¸ ìƒìœ„ 10%
            thr3 = df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"].quantile(0.90)
            df_anom["ì´ìƒ_ê³ ê°€"] = df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"] >= thr3

            df_anom["ì´ìƒê±°ë˜"] = df_anom["ì´ìƒ_ë¹„ìœ¨"] | df_anom["ì´ìƒ_ê³ ê°€"]

            anom_only = df_anom[df_anom["ì´ìƒê±°ë˜"]].copy()

            st.write(f"ë°œê²¬ëœ ì´ìƒ ê±°ë˜ ìˆ˜: **{len(anom_only):,} ê±´**")

            if len(anom_only) < 10:
                st.info("ì´ìƒ ê±°ë˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ í´ëŸ¬ìŠ¤í„°ë§ì´ ì–´ë µìŠµë‹ˆë‹¤.")
            else:
                use_cols2 = [
                    "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)", "ë¹„ìœ¨", "ê±´ì¶•ë…„ë„"
                ]
                use_cols2 = [c for c in use_cols2 if c in anom_only.columns]

                data_k2 = anom_only[use_cols2].dropna().copy()

                if len(data_k2) < 10:
                    st.info("ìœ íš¨í•œ ì´ìƒ ê±°ë˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    k2 = st.slider("í´ëŸ¬ìŠ¤í„° ìˆ˜ (K)", min_value=2, max_value=8, value=3, key="anom_k")

                    scaler2 = StandardScaler()
                    scaled2 = scaler2.fit_transform(data_k2)

                    model2 = KMeans(n_clusters=k2, random_state=42, n_init="auto")
                    labels2 = model2.fit_predict(scaled2)
                    data_k2["cluster"] = labels2
                    data_k2["cluster"] = data_k2["cluster"].astype(int)

                    result2 = data_k2.merge(
                        anom_only[["êµ¬", "ë™", "ë‹¨ì§€ëª…", "ê³„ì•½ë…„ì›”", "ì „ì›”ì„¸êµ¬ë¶„"]],
                        left_index=True,
                        right_index=True,
                        how="left"
                    )

                    st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìƒ˜í”Œ")
                    st.dataframe(result2.head(50))

                    st.download_button(
                        "ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                        result2.to_csv(index=False).encode("utf-8-sig"),
                        file_name=f"{selected_gu}_{selected_dong}_í´ëŸ¬ìŠ¤í„°ë§_ì´ìƒê±°ë˜.csv"
                    )

                    st.write("#### ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’")
                    summary_k2 = data_k2.groupby("cluster").mean()
                    st.dataframe(summary_k2)

                    if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(data_k2.columns):
                        chart2 = data_k2.reset_index(drop=True).copy()
                        chart2["cluster"] = chart2["cluster"].astype(str)

                        scatter2 = (
                            alt.Chart(chart2)
                            .mark_circle(size=60, opacity=0.6)
                            .encode(
                                x="ì „ìš©ë©´ì (ã¡):Q",
                                y="ì›”ì„¸ê¸ˆ(ë§Œì›):Q",
                                color="cluster:N",
                                tooltip=["cluster", "ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë³´ì¦ê¸ˆ(ë§Œì›)"]
                            )
                        )
                        st.write("#### ğŸ¨ ì „ìš©ë©´ì  vs ì›”ì„¸ (ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°)")
                        st.altair_chart(scatter2, use_container_width=True)
