import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import matplotlib.pyplot as plt
from scipy import stats
import io
import matplotlib.font_manager as fm
import os
from dotenv import load_dotenv
load_dotenv() 
from crewai import Agent, Task, Crew, Process 
from crewai_reports import (
    run_recommendation_report,
    run_condition_coach_report,
    run_comparison_report,
    run_market_rarity_report,
)
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
assert OPENAI_API_KEY is not None, "ğŸš¨ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"
# ê°€ìƒí™˜ê²½ ì§„ì…: W03_env\Scripts\activate.bat

# =========================
# í°íŠ¸ ì„¤ì •
# =========================
font_path = os.path.join(os.path.dirname(__file__), "fonts", "NanumGothic.ttf")
fm.fontManager.addfont(font_path)
font_prop = fm.FontProperties(fname=font_path)
plt.rcParams["font.family"] = font_prop.get_name()
plt.rcParams["axes.unicode_minus"] = False

# =========================
# ê³µí†µ ìµœì†Œ í‘œë³¸ ìˆ˜ ì„¤ì •
# =========================
MIN_RENT_FOR_BASIC = 5       # ì•„ì£¼ ê°„ë‹¨í•œ í†µê³„/ë¶„í¬ í™•ì¸
MIN_RENT_FOR_DIST = 10       # íˆìŠ¤í† ê·¸ë¨/QQPlot ë“± ë¶„í¬ ë¶„ì„
MIN_RENT_FOR_CLUSTER = 5     # í´ëŸ¬ìŠ¤í„°ë§ ìµœì†Œ í‘œë³¸ ìˆ˜
MIN_RENT_FOR_HEDONIC = 20    # Hedonic íšŒê·€ ìµœì†Œ í‘œë³¸ ìˆ˜(ì™„í™”)

# ê²°ì¸¡ í—ˆìš© ë¹„ìœ¨ (Hedonicì—ì„œ ì‚¬ìš©)
MIN_NONMISSING_RATIO = 0.5   # ì „ì²´ì˜ 50% ì´ìƒ ê°’ì´ ìˆì„ ë•Œë§Œ ì„¤ëª…ë³€ìˆ˜ë¡œ ì‚¬ìš©


# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(
    page_title="ì„œìš¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë¶„ì„ (ì˜¤í”¼ìŠ¤í…”/ì•„íŒŒíŠ¸/ì—°ë¦½ë‹¤ì„¸ëŒ€)",
    layout="wide"
)

# ========= SessionState ê¸°ë³¸ê°’ =========
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    st.session_state.page = "ì„œìš¸ ì „ì²´ ìš”ì•½"
    st.session_state.selected_housing = "ì „ì²´"
    st.session_state.selected_gu = None
    st.session_state.selected_dong = "ì „ì²´"


st.title("ì„œìš¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ë¦¬ë¹Œë”© Ver., ì›”ì„¸ ì „ìš©)")

st.caption("""
- í˜ì´ì§€ êµ¬ì¡°: **ì„œìš¸ ì „ì²´ ìš”ì•½ â†’ êµ¬ë³„ ë¶„ì„ â†’ ì´ìƒ ê±°ë˜ íƒìƒ‰ â†’ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ â†’ ìš”ì¸ ë¶„ì„ â†’ AI ì •ì„± ë¶„ì„(CrewAI)**  
- ë¶„ì„ ëŒ€ìƒ: **ì˜¤í”¼ìŠ¤í…” / ì•„íŒŒíŠ¸ / ì—°ë¦½ë‹¤ì„¸ëŒ€** **ì›”ì„¸ ì‹¤ê±°ë˜**(ì „ì„¸/ì›”ì„¸ 0ì› ê±°ë˜ëŠ” ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì œê±°).  
- ì›”ì„¸ ê´€ë ¨ ëª¨ë“  ë¶„ì„ì€ **ì›”ì„¸ê¸ˆ(ë§Œì›) > 0ì¸ ê±°ë˜**ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
""")


# =========================
# 1. ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬
# =========================
@st.cache_data(show_spinner=True)
def load_data() -> pd.DataFrame:
    """
    ê° ì£¼íƒìœ í˜• íŒŒì¼ì„ ë¡œë”©í•˜ê³  ê³µí†µ ì»¬ëŸ¼ëª…ì„ ë§ì¶˜ ë’¤,
    ê¸ˆì•¡/ë©´ì /ë…„ë„ ë“±ì„ ìˆ«ìë¡œ ë³€í™˜í•˜ê³ ,
    ìµœì¢…ì ìœ¼ë¡œ **ì›”ì„¸ ê±°ë˜ë§Œ ë‚¨ê¸´ DataFrame**ì„ ë°˜í™˜.
    """
    file_paths = {
        "ì˜¤í”¼ìŠ¤í…”": "ì˜¤í”¼ìŠ¤í…”(ì „ì›”ì„¸)_ì‹¤ê±°ë˜ê°€_ì§€í•˜ì² ì—­ê±°ë¦¬_ì§€ìˆ˜ê°ì‡ _ê°€ê²©ì¶”ê°€.csv",
        "ì•„íŒŒíŠ¸": "APT_geocoded_ì›”ì„¸_ê²°ì¸¡ì œê±°_ì—­ê±°ë¦¬_ì§€ìˆ˜ê°ì‡ _ê°€ê²©ì¶”ê°€.csv",
        "ì—°ë¦½ë‹¤ì„¸ëŒ€": "DSD_geocoded_ì›”ì„¸_ê²°ì¸¡ì œê±°_ì—­ê±°ë¦¬_ì§€ìˆ˜ê°ì‡ _ê°€ê²©ì¶”ê°€.csv",
    }

    df_list = []
    missing = []

    for htype, path in file_paths.items():
        if not os.path.exists(path):
            missing.append(f"{htype}: {path}")
            continue

        tmp = pd.read_csv(path, encoding="utf-8-sig")

        # --- ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼ëª… í†µì¼ -----------------------------------
        if "ë³´ì¦ê¸ˆ(ë§Œì›)" not in tmp.columns:
            cand_dep = [c for c in tmp.columns if "ë³´ì¦ê¸ˆ" in c]
            if cand_dep:
                tmp.rename(columns={cand_dep[0]: "ë³´ì¦ê¸ˆ(ë§Œì›)"}, inplace=True)

        if "ì›”ì„¸ê¸ˆ(ë§Œì›)" not in tmp.columns:
            cand_rent = [c for c in tmp.columns if ("ì›”ì„¸" in c and "ë§Œ" in c)]
            if cand_rent:
                tmp.rename(columns={cand_rent[0]: "ì›”ì„¸ê¸ˆ(ë§Œì›)"}, inplace=True)

        if "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)" not in tmp.columns:
            cand_prev_dep = [c for c in tmp.columns if ("ì¢…ì „" in c and "ë³´ì¦ê¸ˆ" in c)]
            if cand_prev_dep:
                tmp.rename(columns={cand_prev_dep[0]: "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)"}, inplace=True)

        if "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)" not in tmp.columns:
            cand_prev_rent = [c for c in tmp.columns if ("ì¢…ì „" in c and "ì›”ì„¸" in c)]
            if cand_prev_rent:
                tmp.rename(columns={cand_prev_rent[0]: "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"}, inplace=True)
        # -------------------------------------------------------------

        # --- ì£¼íƒìœ í˜• í†µì¼ ---
        if "ì£¼íƒìœ í˜•" not in tmp.columns:
            tmp["ì£¼íƒìœ í˜•"] = htype
        else:
            tmp["ì£¼íƒìœ í˜•"] = tmp["ì£¼íƒìœ í˜•"].fillna(htype)

        # --- ì „ì›”ì„¸êµ¬ë¶„ í†µì¼ (ê±°ì˜ ëª¨ë‘ ì›”ì„¸ì§€ë§Œ í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš° ëŒ€ë¹„) ---
        if "ì „ì›”ì„¸êµ¬ë¶„" not in tmp.columns:
            tmp["ì „ì›”ì„¸êµ¬ë¶„"] = "ì›”ì„¸"
        else:
            tmp["ì „ì›”ì„¸êµ¬ë¶„"] = tmp["ì „ì›”ì„¸êµ¬ë¶„"].fillna("ì›”ì„¸")

        df_list.append(tmp)

    if missing:
        st.warning("ë‹¤ìŒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:\n" + "\n".join(missing))

    if not df_list:
        st.error("ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df = pd.concat(df_list, ignore_index=True)

    # ğŸ”§ (1) ì—­ ê±°ë¦¬ / ì ‘ê·¼ì„± / ê°€ê²© ì»¬ëŸ¼ëª… í†µì¼ ------------------------
    if "ê°€ê¹Œìš´ì—­ê¹Œì§€_ê±°ë¦¬_m" in df.columns and "ì—­ê¹Œì§€ê±°ë¦¬(m)" not in df.columns:
        df.rename(columns={"ê°€ê¹Œìš´ì—­ê¹Œì§€_ê±°ë¦¬_m": "ì—­ê¹Œì§€ê±°ë¦¬(m)"}, inplace=True)

    if "ì—­_ì ‘ê·¼ì„±_ì§€ìˆ˜ê°ì‡ " in df.columns and "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜" not in df.columns:
        df.rename(columns={"ì—­_ì ‘ê·¼ì„±_ì§€ìˆ˜ê°ì‡ ": "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"}, inplace=True)

    if "ì—­ê¹Œì§€ê±°ë¦¬(m)" in df.columns:
        df["ì—­ê¹Œì§€ê±°ë¦¬(m)"] = pd.to_numeric(df["ì—­ê¹Œì§€ê±°ë¦¬(m)"], errors="coerce")

    if "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜" in df.columns:
        df["ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"] = pd.to_numeric(df["ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"], errors="coerce")

    # ê°€ê²© ì»¬ëŸ¼: íŒŒì¼ì— ì´ë¯¸ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê³„ì‚°
    if "ê°€ê²©" not in df.columns and {"ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(df.columns):
        df["ê°€ê²©"] = df["ë³´ì¦ê¸ˆ(ë§Œì›)"] * 0.375 + df["ì›”ì„¸ê¸ˆ(ë§Œì›)"]
    # -------------------------------------------------------------

    # ê¸°ì¡´ ì´ì§„ ì—­ì„¸ê¶Œ ë³€ìˆ˜ ì œê±° (ìˆì„ ë•Œë§Œ)
    if "ì—­ì„¸ê¶Œ" in df.columns:
        df = df.drop(columns=["ì—­ì„¸ê¶Œ"])

    # ğŸ”§ ê¸ˆì•¡í˜• ì»¬ëŸ¼ ìˆ«ìë¡œ ë³€í™˜
    money_cols = ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"]
    for col in money_cols:
        if col in df.columns:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(",", "", regex=False)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")

    num_cols = ["ê³„ì•½ë…„ì›”", "ê³„ì•½ì¼", "ì¸µ", "ê±´ì¶•ë…„ë„"]
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    if "ì „ìš©ë©´ì (ã¡)" in df.columns:
        df["ì „ìš©ë©´ì (ã¡)"] = pd.to_numeric(df["ì „ìš©ë©´ì (ã¡)"], errors="coerce")

    # ì‹œêµ°êµ¬ â†’ ì‹œë„ / êµ¬ / ë™ ë¶„ë¦¬
    if "ì‹œêµ°êµ¬" in df.columns:
        loc = df["ì‹œêµ°êµ¬"].astype(str).str.split()
        df["ì‹œë„"] = loc.str[0]
        df["êµ¬"] = loc.str[1]
        df["ë™"] = loc.str[2]

    # ì „ìš©ë©´ì ë‹¹ ì›”ì„¸
    if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(df.columns):
        df["ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)"] = np.where(
            (df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0) & (df["ì „ìš©ë©´ì (ã¡)"] > 0),
            df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / df["ì „ìš©ë©´ì (ã¡)"],
            np.nan
        )

    # ì›”ì„¸ê³„ì•½ ì—¬ë¶€
    if "ì›”ì„¸ê¸ˆ(ë§Œì›)" in df.columns:
        df["ì›”ì„¸ê³„ì•½ì—¬ë¶€"] = df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0

        # âœ… ìµœì¢…ì ìœ¼ë¡œ ì›”ì„¸ ê±°ë˜ë§Œ ë‚¨ê¹€ (ì „ì„¸/ì›”ì„¸0 ì œê±°)
        df = df[df["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0].copy()

    return df


df = load_data()
if df.empty:
    st.stop()

all_gu = sorted(df["êµ¬"].dropna().unique())


# =========================
# 2. ì‚¬ì´ë“œë°” ì„¤ì • (í˜ì´ì§€ & í•„í„°)
# =========================
st.sidebar.title("ì„¤ì •")

selected_gu = None
selected_dong = "ì „ì²´"
selected_housing = "ì „ì²´"

# â‘  ê¸°ë³¸ ì„ íƒ
with st.sidebar.expander("â‘  ê¸°ë³¸ ì„ íƒ", expanded=True):
    pages_list = [
        "ì„œìš¸ ì „ì²´ ìš”ì•½",
        "êµ¬ë³„ ë¶„ì„",
        "ì´ìƒ ê±°ë˜ íƒìƒ‰",
        "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„",
        "ìš”ì¸ ë¶„ì„",
        "AI ì •ì„± ë¶„ì„"
    ]
    housing_type_options = ["ì „ì²´", "ì˜¤í”¼ìŠ¤í…”", "ì•„íŒŒíŠ¸", "ì—°ë¦½ë‹¤ì„¸ëŒ€"]

    st.session_state.page = st.radio(
        "í˜ì´ì§€ ì„ íƒ",
        pages_list,
        index=pages_list.index(st.session_state.page) if st.session_state.page in pages_list else 0
    )

    st.session_state.selected_housing = st.selectbox(
        "ì£¼íƒìœ í˜• ì„ íƒ",
        options=housing_type_options,
        index=housing_type_options.index(st.session_state.selected_housing)
        if st.session_state.selected_housing in housing_type_options else 0
    )

    if st.session_state.page != "ì„œìš¸ ì „ì²´ ìš”ì•½":
        default_gu = "ê°•ë‚¨êµ¬" if "ê°•ë‚¨êµ¬" in all_gu else all_gu[0]
        init_gu = st.session_state.selected_gu if st.session_state.selected_gu in all_gu else default_gu

        selected_gu = st.selectbox(
            "êµ¬ ì„ íƒ",
            options=all_gu,
            index=all_gu.index(init_gu)
        )
        st.session_state.selected_gu = selected_gu

        dongs_in_gu = sorted(
            df[df["êµ¬"] == selected_gu]["ë™"].dropna().unique()
        )
        init_dong_list = ["ì „ì²´"] + dongs_in_gu
        init_dong = st.session_state.selected_dong if st.session_state.selected_dong in init_dong_list else "ì „ì²´"

        selected_dong = st.selectbox(
            "ë™ ì„ íƒ (ì „ì²´ ë³´ë ¤ë©´ 'ì „ì²´')",
            options=init_dong_list,
            index=init_dong_list.index(init_dong)
        )
        st.session_state.selected_dong = selected_dong
    else:
        selected_gu = None
        selected_dong = "ì „ì²´"
        st.session_state.selected_gu = None
        st.session_state.selected_dong = "ì „ì²´"

# í¸ì˜ìš© ë¡œì»¬ ë³€ìˆ˜
page = st.session_state.page
selected_housing = st.session_state.selected_housing
selected_gu = st.session_state.selected_gu
selected_dong = st.session_state.selected_dong


def get_loc_label(gu, dong, housing_type):
    if gu is None:
        base = "ì„œìš¸ ì „ì²´"
    elif dong == "ì „ì²´":
        base = f"{gu}"
    else:
        base = f"{gu} {dong}"

    if housing_type and housing_type != "ì „ì²´":
        return f"{housing_type} Â· {base}"
    else:
        return f"{base} (ì „ì²´ ì£¼íƒìœ í˜•)"


loc_label = get_loc_label(selected_gu, selected_dong, selected_housing)

# â‘¡ ì„¸ë¶€ í•„í„°
with st.sidebar.expander("â‘¡ ì„¸ë¶€ í•„í„°", expanded=(page != "ì„œìš¸ ì „ì²´ ìš”ì•½")):
    # ì „ì›”ì„¸êµ¬ë¶„ì€ ì‚¬ì‹¤ìƒ ëª¨ë‘ ì›”ì„¸ì´ì§€ë§Œ, UI ì¼ê´€ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ 
    all_type = sorted(df["ì „ì›”ì„¸êµ¬ë¶„"].dropna().unique()) if "ì „ì›”ì„¸êµ¬ë¶„" in df.columns else []
    default_type = [t for t in all_type if "ì›”ì„¸" in t] or all_type
    selected_type = st.multiselect(
        "ì „ì›”ì„¸ êµ¬ë¶„ (ì‹¤ì œ ë°ì´í„°ëŠ” ëŒ€ë¶€ë¶„ ì›”ì„¸)",
        options=all_type,
        default=default_type
    )

    if "ì „ìš©ë©´ì (ã¡)" in df.columns:
        min_area = float(np.nanmin(df["ì „ìš©ë©´ì (ã¡)"]))
        max_area = float(np.nanmax(df["ì „ìš©ë©´ì (ã¡)"]))
        area_range = st.slider(
            "ì „ìš©ë©´ì  ë²”ìœ„ (ã¡)",
            min_value=float(round(min_area, 1)),
            max_value=float(round(max_area, 1)),
            value=(float(round(min_area, 1)), float(round(max_area, 1)))
        )
    else:
        area_range = None

    if "ê±´ì¶•ë…„ë„" in df.columns:
        min_year = int(np.nanmin(df["ê±´ì¶•ë…„ë„"]))
        max_year = int(np.nanmax(df["ê±´ì¶•ë…„ë„"]))
        year_range = st.slider(
            "ê±´ì¶•ë…„ë„ ë²”ìœ„",
            min_value=min_year,
            max_value=max_year,
            value=(min_year, max_year)
        )
    else:
        year_range = None

    only_renew = st.checkbox("ê°±ì‹  ê³„ì•½ë§Œ ë³´ê¸° (ê³„ì•½êµ¬ë¶„ == 'ê°±ì‹ ')", value=False)

with st.sidebar.expander("â‘¢ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´", expanded=False):
    st.caption("ê° í˜ì´ì§€ í•˜ë‹¨ì—ì„œ **í•„í„° ì ìš© ë°ì´í„° / ì´ìƒ ê±°ë˜ / í´ëŸ¬ìŠ¤í„° ê²°ê³¼**ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# 3. ê³µí†µ í•„í„° í•¨ìˆ˜ + ì›”ì„¸ ì „ìš© í•„í„° (ìºì‹œ ì‚¬ìš©)
# =========================
@st.cache_data(show_spinner=False)
def apply_common_filters_cached(
    df_in: pd.DataFrame,
    selected_housing: str,
    gu: str | None,
    dong: str,
    selected_type_tuple: tuple,
    area_range: tuple | None,
    year_range: tuple | None,
    only_renew: bool
) -> pd.DataFrame:
    df_out = df_in.copy()

    if selected_housing != "ì „ì²´" and "ì£¼íƒìœ í˜•" in df_out.columns:
        df_out = df_out[df_out["ì£¼íƒìœ í˜•"] == selected_housing]

    if gu is not None:
        df_out = df_out[df_out["êµ¬"] == gu]

    if dong != "ì „ì²´":
        df_out = df_out[df_out["ë™"] == dong]

    if "ì „ì›”ì„¸êµ¬ë¶„" in df_out.columns and selected_type_tuple:
        df_out = df_out[df_out["ì „ì›”ì„¸êµ¬ë¶„"].isin(list(selected_type_tuple))]

    if area_range is not None and "ì „ìš©ë©´ì (ã¡)" in df_out.columns:
        df_out = df_out[
            (df_out["ì „ìš©ë©´ì (ã¡)"] >= area_range[0]) &
            (df_out["ì „ìš©ë©´ì (ã¡)"] <= area_range[1])
        ]

    if year_range is not None and "ê±´ì¶•ë…„ë„" in df_out.columns:
        df_out = df_out[
            (df_out["ê±´ì¶•ë…„ë„"] >= year_range[0]) &
            (df_out["ê±´ì¶•ë…„ë„"] <= year_range[1])
        ]

    if only_renew and "ê³„ì•½êµ¬ë¶„" in df_out.columns:
        df_out = df_out[df_out["ê³„ì•½êµ¬ë¶„"] == "ê°±ì‹ "]

    return df_out


def apply_common_filters(df_in, gu=None, dong="ì „ì²´"):
    type_tuple = tuple(sorted(selected_type)) if selected_type else tuple()
    return apply_common_filters_cached(
        df_in,
        selected_housing,
        gu,
        dong,
        type_tuple,
        area_range,
        year_range,
        only_renew
    )


@st.cache_data(show_spinner=False)
def get_rent_only(df_in: pd.DataFrame) -> pd.DataFrame:
    """
    ì›”ì„¸ ê±°ë˜ë§Œ ë½‘ì•„ì„œ ëŒë ¤ì£¼ëŠ” ê³µí†µ í•¨ìˆ˜.
    (í˜„ì¬ ë°ì´í„°ëŠ” ì´ë¯¸ ì›”ì„¸-onlyì§€ë§Œ, ì•ˆì „í•˜ê²Œ í•œ ë²ˆ ë” í•„í„°)
    """
    if len(df_in) == 0:
        return df_in

    df_out = df_in.copy()

    if "ì›”ì„¸ê¸ˆ(ë§Œì›)" in df_out.columns:
        return df_out[df_out["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > 0]

    if "ì „ì›”ì„¸êµ¬ë¶„" in df_out.columns:
        mask = df_out["ì „ì›”ì„¸êµ¬ë¶„"].astype(str).str.contains("ì›”ì„¸", na=False)
        return df_out[mask]

    return df_out.iloc[0:0]


# =========================
# 3.5. AI ì •ì„± ë¶„ì„ìš© í—¬í¼ í•¨ìˆ˜ë“¤
# =========================
def build_user_condition_text(housing_type, gu, dong, area_range, year_range, only_renew):
    lines = []
    if housing_type and housing_type != "ì „ì²´":
        lines.append(f"- ì£¼íƒìœ í˜•: {housing_type}")
    else:
        lines.append("- ì£¼íƒìœ í˜•: ì „ì²´")

    if gu is None:
        lines.append("- ì§€ì—­: ì„œìš¸ ì „ì²´")
    elif dong == "ì „ì²´":
        lines.append(f"- ì§€ì—­: {gu} ì „ì²´")
    else:
        lines.append(f"- ì§€ì—­: {gu} {dong}")

    if area_range is not None:
        lines.append(f"- ì „ìš©ë©´ì  ë²”ìœ„: {area_range[0]:.1f} ~ {area_range[1]:.1f}ã¡")

    if year_range is not None:
        lines.append(f"- ê±´ì¶•ë…„ë„ ë²”ìœ„: {year_range[0]} ~ {year_range[1]}ë…„")

    lines.append(f"- ê°±ì‹  ê³„ì•½ë§Œ ë³´ê¸°: {'ì˜ˆ' if only_renew else 'ì•„ë‹ˆì˜¤'}")

    return "\n".join(lines)


def build_candidates_text(df_candidates: pd.DataFrame, max_rows: int = 10) -> str:
    """í›„ë³´ ë§¤ë¬¼ë“¤ì„ CrewAIì— ë„˜ê¸¸ ìˆ˜ ìˆê²Œ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬."""
    if df_candidates.empty:
        return "í›„ë³´ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤."

    rows = []
    use_cols = [
        "ì£¼íƒìœ í˜•",
        "êµ¬",
        "ë™",
        "ë„ë¡œëª…",
        "ì „ìš©ë©´ì (ã¡)",
        "ë³´ì¦ê¸ˆ(ë§Œì›)",
        "ì›”ì„¸ê¸ˆ(ë§Œì›)",
        "ê°€ê²©",
        "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜",
        "ì—­ê¹Œì§€ê±°ë¦¬(m)",
        "ê±´ì¶•ë…„ë„",
        "ì¸µ",
    ]
    cols = [c for c in use_cols if c in df_candidates.columns]

    for i, (_, r) in enumerate(df_candidates.head(max_rows).iterrows(), start=1):
        parts = [f"{c}: {r[c]}" for c in cols]
        rows.append(f"{i}) " + ", ".join(parts))

    return "\n".join(rows)


def build_condition_scenario_text(scenarios: list[dict]) -> str:
    """
    ì¡°ê±´ ì™„í™” ì‹œë‚˜ë¦¬ì˜¤ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨.
    ê° scenario dictëŠ” {name, description, count, examples_df} í˜•íƒœë¥¼ ê°€ì •.
    """
    lines: list[str] = []
    for s in scenarios:
        lines.append(f"ì‹œë‚˜ë¦¬ì˜¤: {s['name']}")
        lines.append(f"- ì„¤ëª…: {s['description']}")
        lines.append(f"- ë§¤ë¬¼ ìˆ˜: {s['count']}ê±´")
        if s.get("examples_df") is not None and not s["examples_df"].empty:
            ex = s["examples_df"].head(3)[
                [c for c in ["êµ¬", "ë™", "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"] if c in s["examples_df"].columns]
            ]
            lines.append("- ëŒ€í‘œ ë§¤ë¬¼ ì˜ˆì‹œ (3ê±´):")
            lines.append(ex.to_string(index=False))
        lines.append("")  # ë¹ˆ ì¤„
    return "\n".join(lines)


def build_comparison_text(df_comp: pd.DataFrame) -> str:
    """
    ì§€ì—­/ìœ í˜• ë¹„êµìš© í…ìŠ¤íŠ¸.
    ì˜ˆ: êµ¬Â·ì£¼íƒìœ í˜•ë³„ ë³´ì¦ê¸ˆ/ì›”ì„¸/ë©´ì /ì—­ê±°ë¦¬ í‰ê· .
    """
    if df_comp.empty:
        return "ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    group_cols = []
    if "êµ¬" in df_comp.columns:
        group_cols.append("êµ¬")
    if "ì£¼íƒìœ í˜•" in df_comp.columns:
        group_cols.append("ì£¼íƒìœ í˜•")

    if not group_cols:
        return "êµ¬/ì£¼íƒìœ í˜• ì»¬ëŸ¼ì´ ì—†ì–´ ë¹„êµ ìš”ì•½ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    num_cols = [c for c in ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì „ìš©ë©´ì (ã¡)", "ì—­ê¹Œì§€ê±°ë¦¬(m)"] if c in df_comp.columns]

    agg = (
        df_comp.groupby(group_cols)[num_cols]
        .agg(["count", "mean"])
        .reset_index()
    )

    lines = ["[ì§€ì—­/ìœ í˜•ë³„ ìš”ì•½ í†µê³„]"]
    lines.append(agg.head(30).to_string(index=False))
    return "\n".join(lines)


def build_market_rarity_text(df_all: pd.DataFrame, df_filtered: pd.DataFrame, condition_text: str) -> str:
    """
    ì‹œì¥ í¬ì†Œì„± ë¸Œë¦¬í•‘ìš© ìš”ì•½ í…ìŠ¤íŠ¸.
    df_all: ì „ì²´(ì¡°ê±´ ëœ íƒ„) ë°ì´í„°
    df_filtered: í˜„ì¬ ì¡°ê±´ ë°ì´í„°
    """
    total = len(df_all)
    current = len(df_filtered)

    if total == 0:
        return "ì „ì²´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    ratio = current / total * 100
    lines = [
        "[ì‹œì¥ í¬ì†Œì„± ê¸°ì´ˆ ì •ë³´]",
        f"- ì „ì²´ ë§¤ë¬¼ ìˆ˜: {total}ê±´",
        f"- í˜„ì¬ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë§¤ë¬¼ ìˆ˜: {current}ê±´",
        f"- ë¹„ì¤‘: {ratio:.2f}%",
        "",
        "[í˜„ì¬ ì¡°ê±´ ìš”ì•½]",
        condition_text,
        "",
    ]

    # ë³´ë„ˆìŠ¤: ì „ì²´ vs í•„í„° í‰ê·  ë¹„êµ
    for col in ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì „ìš©ë©´ì (ã¡)", "ì—­ê¹Œì§€ê±°ë¦¬(m)"]:
        if col in df_all.columns and not df_filtered.empty and col in df_filtered.columns:
            overall_mean = df_all[col].mean()
            current_mean = df_filtered[col].mean()
            lines.append(
                f"- {col} ì „ì²´ í‰ê· : {overall_mean:.1f}, í˜„ì¬ ì¡°ê±´ í‰ê· : {current_mean:.1f}"
            )

    return "\n".join(lines)


# =========================
# 4. í˜ì´ì§€ 1: ì„œìš¸ ì „ì²´ ìš”ì•½
# =========================
if page == "ì„œìš¸ ì „ì²´ ìš”ì•½":
    title_htype = "ì „ì²´ ì£¼íƒìœ í˜•" if selected_housing == "ì „ì²´" else selected_housing
    st.header(f"ğŸ“ ì„œìš¸ ì „ì²´ ìš”ì•½ ({title_htype}, ì›”ì„¸ ê±°ë˜ ê¸°ì¤€)")

    df_overall = apply_common_filters(df, gu=None, dong="ì „ì²´")
    df_rent = get_rent_only(df_overall)

    st.write(f"#### ğŸ” ë°ì´í„° ìƒ˜í”Œ (ì£¼íƒìœ í˜• í•„í„°: **{title_htype}**, ì›”ì„¸ë§Œ)")
    st.dataframe(df_rent.head())

    st.write("---")
    st.subheader(f"ğŸ™ï¸ êµ¬ë³„ ì›”ì„¸ ê±°ë˜ ìš”ì•½ ({title_htype})")

    summary = (
        df_rent.groupby("êµ¬")
        .agg(
            ê±°ë˜ìˆ˜=("NO", "count"),
            í‰ê· ë³´ì¦ê¸ˆ=("ë³´ì¦ê¸ˆ(ë§Œì›)", "mean"),
            í‰ê· ì›”ì„¸=("ì›”ì„¸ê¸ˆ(ë§Œì›)", "mean"),
            í‰ê· ê°€ê²©=("ê°€ê²©", "mean")
        )
        .reset_index()
    )

    st.dataframe(summary)

    st.download_button(
        "êµ¬ë³„ ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
        summary.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"ì„œìš¸_êµ¬ë³„_ìš”ì•½_{title_htype}_ì›”ì„¸.csv"
    )

    st.write(f"#### ğŸ“Š êµ¬ë³„ í‰ê·  ì›”ì„¸ (ì›”ì„¸ ê±°ë˜ë§Œ, {title_htype})")

    if len(df_rent) > 0:
        avg_rent_by_gu = (
            df_rent.groupby("êµ¬")["ì›”ì„¸ê¸ˆ(ë§Œì›)"]
            .mean()
            .reset_index()
        )

        chart = (
            alt.Chart(avg_rent_by_gu)
            .mark_bar()
            .encode(
                x=alt.X("êµ¬:N", sort="-y", title="êµ¬"),
                y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="í‰ê·  ì›”ì„¸ (ë§Œì›)"),
                tooltip=["êµ¬", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]
            )
            .properties(title=f"êµ¬ë³„ í‰ê·  ì›”ì„¸ (ì£¼íƒìœ í˜•: {title_htype})")
        )
        st.altair_chart(chart, use_container_width=True)
    else:
        st.info("ì›”ì„¸ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.write("---")
    st.caption("â€» ë‹¤ë¥¸ í˜ì´ì§€ì—ì„œ êµ¬ì™€ ë™ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ êµ¬Â·ë™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìì„¸í•œ ë¶„ì„ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# 5. í˜ì´ì§€ 2: êµ¬ë³„ ë¶„ì„
# =========================
elif page == "êµ¬ë³„ ë¶„ì„":
    st.header(f"ğŸ™ï¸ {loc_label} ìƒì„¸ ë¶„ì„ (ì›”ì„¸ ê±°ë˜ ê¸°ì¤€)")

    filtered = apply_common_filters(df, gu=selected_gu, dong=selected_dong)

    if len(filtered) == 0:
        st.info("í˜„ì¬ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì¡°ê±´ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
    else:
        rent_df = get_rent_only(filtered)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(f"{loc_label} ì „ì²´ ì›”ì„¸ ê±°ë˜ ìˆ˜", f"{len(rent_df):,} ê±´")
        with col2:
            avg_deposit = rent_df["ë³´ì¦ê¸ˆ(ë§Œì›)"].mean()
            st.metric("í‰ê·  ë³´ì¦ê¸ˆ (ë§Œì›)", f"{avg_deposit:,.0f}")
        with col3:
            avg_rent = rent_df["ì›”ì„¸ê¸ˆ(ë§Œì›)"].mean()
            st.metric("í‰ê·  ì›”ì„¸ (ë§Œì›)", f"{avg_rent:,.0f}")

        st.write("---")
        st.subheader(f"ğŸ’° ì›”ì„¸ ê±°ë˜ ë¶„í¬ ({loc_label})")

        if len(rent_df) > 0:
            data = rent_df["ì›”ì„¸ê¸ˆ(ë§Œì›)"].dropna()

            if data.empty:
                st.info("ìœ íš¨í•œ ì›”ì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                view = st.radio(
                    "í‘œí˜„ ë°©ì‹ ì„ íƒ",
                    ["íˆìŠ¤í† ê·¸ë¨", "ë°•ìŠ¤í”Œë¡¯", "Q-Q Plot (ê³ ê¸‰)"],
                    index=0,
                    horizontal=True
                )

                if view == "íˆìŠ¤í† ê·¸ë¨":
                    rent_hist = (
                        alt.Chart(rent_df)
                        .mark_bar()
                        .encode(
                            x=alt.X(
                                "ì›”ì„¸ê¸ˆ(ë§Œì›):Q",
                                bin=alt.Bin(maxbins=30),
                                title="ì›”ì„¸ (ë§Œì›)"
                            ),
                            y=alt.Y("count():Q", title="ê±°ë˜ ê±´ìˆ˜"),
                            tooltip=["count()"]
                        )
                        .properties(title=f"ì›”ì„¸ íˆìŠ¤í† ê·¸ë¨ ({loc_label})")
                    )
                    st.altair_chart(rent_hist, use_container_width=True)

                    fig, ax = plt.subplots()
                    ax.hist(data, bins=30)
                    ax.set_title(f"{loc_label} Monthly Rent Histogram")
                    ax.set_xlabel("Monthly Rent (10k KRW)")
                    ax.set_ylabel("Number of contracts")

                    buf = io.BytesIO()
                    fig.savefig(buf, format="png", bbox_inches="tight")
                    buf.seek(0)

                    st.download_button(
                        label="Download Histogram (PNG)",
                        data=buf,
                        file_name=f"{loc_label}_rent_histogram.png",
                        mime="image/png"
                    )

                elif view == "ë°•ìŠ¤í”Œë¡¯":
                    fig, ax = plt.subplots()
                    ax.boxplot(data, vert=True, showfliers=True)
                    ax.set_title(f"{loc_label} Monthly Rent Boxplot")
                    ax.set_ylabel("Monthly Rent (10k KRW)")
                    ax.set_xticklabels(["All contracts"])

                    st.pyplot(fig)

                    buf = io.BytesIO()
                    fig.savefig(buf, format="png", bbox_inches="tight")
                    buf.seek(0)

                    st.download_button(
                        label="Download Boxplot (PNG)",
                        data=buf,
                        file_name=f"{loc_label}_rent_boxplot.png",
                        mime="image/png"
                    )

                elif view == "Q-Q Plot (ê³ ê¸‰)":
                    fig, ax = plt.subplots()
                    (theoretical_q, ordered_vals), (slope, intercept, r) = stats.probplot(
                        data, dist="norm", fit=True
                    )

                    ax.scatter(
                        theoretical_q,
                        ordered_vals,
                        alpha=0.7,
                        label="Observed rents"
                    )
                    fitted_line = slope * theoretical_q + intercept
                    ax.plot(
                        theoretical_q,
                        fitted_line,
                        color="red",
                        linewidth=2,
                        label="Reference line (normal fit)"
                    )

                    ax.set_title(f"Q-Q Plot of Monthly Rent ({loc_label})")
                    ax.set_xlabel("Expected values under normality")
                    ax.set_ylabel("Observed monthly rent (10k KRW)")
                    ax.legend(loc="best")
                    st.pyplot(fig)

                    buf = io.BytesIO()
                    fig.savefig(buf, format="png", bbox_inches="tight")
                    buf.seek(0)

                    st.download_button(
                        label="Download Q-Q Plot (PNG)",
                        data=buf,
                        file_name=f"{loc_label}_rent_qqplot.png",
                        mime="image/png"
                    )

            if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(rent_df.columns):
                scatter = (
                    alt.Chart(rent_df)
                    .mark_circle(size=60, opacity=0.6)
                    .encode(
                        x=alt.X("ì „ìš©ë©´ì (ã¡):Q", title="ì „ìš©ë©´ì (ã¡)"),
                        y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="ì›”ì„¸(ë§Œì›)"),
                        tooltip=[
                            "ì£¼íƒìœ í˜•",
                            "êµ¬", "ë™",
                            "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in rent_df.columns else "ê±´ë¬¼ëª…",
                            "ì „ìš©ë©´ì (ã¡)",
                            "ë³´ì¦ê¸ˆ(ë§Œì›)",
                            "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                            "ì¸µ",
                            "ê±´ì¶•ë…„ë„",
                            "ê³„ì•½ë…„ì›”"
                        ]
                    )
                    .properties(title=f"ì „ìš©ë©´ì  vs ì›”ì„¸ ì‚°ì ë„ ({loc_label})")
                )
                st.write(f"#### ğŸ“ˆ ì „ìš©ë©´ì  vs ì›”ì„¸ (ì›”ì„¸ ê±°ë˜ë§Œ, {loc_label})")
                st.altair_chart(scatter, use_container_width=True)
        else:
            st.info("ì›”ì„¸ ê±°ë˜ê°€ ì—†ì–´ ì›”ì„¸ ë¶„í¬ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.write("#### ğŸ“‹ í•„í„° ì ìš©ëœ ìƒì„¸ ë°ì´í„° (ì›”ì„¸)")
        st.dataframe(rent_df)

        st.download_button(
            f"{selected_gu}_{selected_dong}_í•„í„°_ì ìš©_ë°ì´í„°.csv ë‹¤ìš´ë¡œë“œ",
            rent_df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_í•„í„°_ë°ì´í„°_ì›”ì„¸.csv"
        )


# =========================
# 6. í˜ì´ì§€ 3: ì´ìƒ ê±°ë˜ íƒìƒ‰
# =========================
elif page == "ì´ìƒ ê±°ë˜ íƒìƒ‰":
    st.header(f"âš  ì´ìƒ ê±°ë˜ íƒìƒ‰ â€“ {loc_label} (ì›”ì„¸ ê¸°ì¤€)")

    base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)
    rent_base = get_rent_only(base)

    st.caption("â€» ëª¨ë“  ê¸°ì¤€ì€ **ì›”ì„¸ê¸ˆ(ë§Œì›) > 0**ì¸ ê±°ë˜ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì „ì„¸ëŠ” ì´ë¯¸ ì œê±°ë¨)")

    if len(base) == 0 or len(rent_base) == 0:
        st.info("í˜„ì¬ í•„í„°ì—ì„œ ë¶„ì„ ê°€ëŠ¥í•œ ì›”ì„¸ ê±°ë˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        tab1, tab2, tab3, tab4 = st.tabs([
            "â‘  ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨",
            "â‘¡ ê°±ì‹  ì‹œ ì¸ìƒë¥ ",
            "â‘¢ ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€",
            "â‘£ í†µê³„ ê¸°ë°˜ (IQR & Q-Q ì´ìƒì¹˜)"
        ])

        # â‘  ë¹„ìœ¨ ê¸°ì¤€
        with tab1:
            st.subheader(f"â‘  ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨ì´ ë†’ì€ ê±°ë˜ ({loc_label})")

            t1 = rent_base.copy()
            t1 = t1[(t1["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0)].copy()
            t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"] = t1["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / t1["ë³´ì¦ê¸ˆ(ë§Œì›)"]

            if len(t1) == 0:
                st.info("ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ê°€ ëª¨ë‘ ìˆëŠ” ì›”ì„¸ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                top_pct = st.slider(
                    "ìƒìœ„ ëª‡ %ë¥¼ ì´ìƒ ê±°ë˜ë¡œ ë³¼ê¹Œìš”?",
                    min_value=5, max_value=30, value=10, step=1
                )
                threshold = t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"].quantile(1 - top_pct / 100)
                anomalies_t1 = t1[t1["ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨"] >= threshold].copy()
                anomalies_t1 = anomalies_t1.sort_values(
                    "ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨", ascending=False
                )

                c1, c2 = st.columns(2)
                with c1:
                    st.metric("ì›”ì„¸ ê±°ë˜ ìˆ˜", f"{len(t1):,} ê±´")
                with c2:
                    st.metric(f"ë¹„ìœ¨ ìƒìœ„ {top_pct}% ê±°ë˜ ìˆ˜", f"{len(anomalies_t1):,} ê±´")

                st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ ë¦¬ìŠ¤íŠ¸ (ë¹„ìœ¨ ê¸°ì¤€)")
                show_cols = [
                    "ì£¼íƒìœ í˜•",
                    "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in anomalies_t1.columns else "ê±´ë¬¼ëª…",
                    "ì „ìš©ë©´ì (ã¡)",
                    "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ë³´ì¦ê¸ˆëŒ€ë¹„ì›”ì„¸ë¹„ìœ¨",
                    "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)",
                    "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”", "ê³„ì•½êµ¬ë¶„"
                ]
                show_cols = [c for c in show_cols if c in anomalies_t1.columns]
                st.dataframe(anomalies_t1[show_cols])

                st.download_button(
                    "ì´ìƒ ê±°ë˜(ë³´ì¦ê¸ˆ ëŒ€ë¹„ ì›”ì„¸ ë¹„ìœ¨) CSV ë‹¤ìš´ë¡œë“œ",
                    anomalies_t1.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ë¹„ìœ¨ê¸°ì¤€.csv"
                )

        # â‘¡ ê°±ì‹  ì¸ìƒë¥ 
        with tab2:
            st.subheader(f"â‘¡ ê°±ì‹  ê³„ì•½ ì¤‘ ì›”ì„¸ ì¸ìƒë¥ ì´ í° ê±°ë˜ ({loc_label})")

            needed = {"ê³„ì•½êµ¬ë¶„", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"}
            if not needed.issubset(base.columns):
                st.warning("ê°±ì‹  ê³„ì•½ ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                t2 = base.copy()
                t2 = t2[
                    (t2["ê³„ì•½êµ¬ë¶„"] == "ê°±ì‹ ") &
                    (t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"] > 0)
                ].copy()

                if len(t2) == 0:
                    st.info("ê°±ì‹  ê³„ì•½(ì¢…ì „ ì›”ì„¸ ì •ë³´ í¬í•¨)ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    t2["ì›”ì„¸ì¸ìƒë¥ (%)"] = (
                        (t2["ì›”ì„¸ê¸ˆ(ë§Œì›)"] - t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"]) /
                        t2["ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)"] * 100
                    )

                    base_pos = t2[t2["ì›”ì„¸ì¸ìƒë¥ (%)"] > 0]

                    if len(base_pos) == 0:
                        st.info("ì›”ì„¸ ì¸ìƒë¥ ì´ ì–‘ìˆ˜ì¸ ê°±ì‹  ê³„ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        top_pct2 = st.slider(
                            "ì›”ì„¸ ì¸ìƒë¥  ìƒìœ„ ëª‡ %ë¥¼ ì´ìƒìœ¼ë¡œ ë³¼ê¹Œìš”?",
                            min_value=5, max_value=30, value=10, step=1
                        )
                        thr2 = base_pos["ì›”ì„¸ì¸ìƒë¥ (%)"].quantile(1 - top_pct2 / 100)
                        anomalies_t2 = base_pos[base_pos["ì›”ì„¸ì¸ìƒë¥ (%)"] >= thr2].copy()
                        anomalies_t2 = anomalies_t2.sort_values(
                            "ì›”ì„¸ì¸ìƒë¥ (%)", ascending=False
                        )

                        c1, c2 = st.columns(2)
                        with c1:
                            st.metric("ê°±ì‹  ê³„ì•½ ìˆ˜", f"{len(base_pos):,} ê±´")
                        with c2:
                            st.metric(
                                f"ì¸ìƒë¥  ìƒìœ„ {top_pct2}% ê±°ë˜ ìˆ˜",
                                f"{len(anomalies_t2):,} ê±´"
                            )

                        show_cols2 = [
                            "ì£¼íƒìœ í˜•",
                            "êµ¬", "ë™",
                            "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in anomalies_t2.columns else "ê±´ë¬¼ëª…",
                            "ì „ìš©ë©´ì (ã¡)",
                            "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                            "ì¢…ì „ê³„ì•½ ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¢…ì „ê³„ì•½ ì›”ì„¸(ë§Œì›)",
                            "ì›”ì„¸ì¸ìƒë¥ (%)",
                            "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”", "ê°±ì‹ ìš”êµ¬ê¶Œ ì‚¬ìš©"
                        ]
                        show_cols2 = [c for c in show_cols2 if c in anomalies_t2.columns]

                        st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ ë¦¬ìŠ¤íŠ¸ (ê°±ì‹  ì¸ìƒë¥  ê¸°ì¤€)")
                        st.dataframe(anomalies_t2[show_cols2])

                        st.download_button(
                            "ì´ìƒ ê±°ë˜(ê°±ì‹  ì¸ìƒë¥ ) CSV ë‹¤ìš´ë¡œë“œ",
                            anomalies_t2.to_csv(index=False).encode("utf-8-sig"),
                            file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ê°±ì‹ ì¸ìƒë¥ .csv"
                        )

        # â‘¢ ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€
        with tab3:
            st.subheader(f"â‘¢ ë¹„ìŠ·í•œ ë©´ì ëŒ€ ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ê³ ê°€ ê±°ë˜ ({loc_label})")

            t3 = rent_base.dropna(subset=["ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]).copy()

            if len(t3) == 0:
                st.info("ì „ìš©ë©´ì ê³¼ ì›”ì„¸ê°€ ëª¨ë‘ ìˆëŠ” ì›”ì„¸ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                bin_size = st.slider(
                    "ì „ìš©ë©´ì  êµ¬ê°„ í­ (ã¡)",
                    min_value=5, max_value=30, value=10, step=5
                )

                min_area = t3["ì „ìš©ë©´ì (ã¡)"].min()
                max_area = t3["ì „ìš©ë©´ì (ã¡)"].max()

                bins = np.arange(
                    np.floor(min_area),
                    np.ceil(max_area) + bin_size,
                    bin_size
                )
                t3["ë©´ì êµ¬ê°„"] = pd.cut(
                    t3["ì „ìš©ë©´ì (ã¡)"],
                    bins=bins,
                    include_lowest=True
                )

                grp = (
                    t3.groupby("ë©´ì êµ¬ê°„")
                    .agg(ë¡œì»¬í‰ê· ì›”ì„¸=("ì›”ì„¸ê¸ˆ(ë§Œì›)", "mean"))
                    .reset_index()
                )

                t3 = t3.merge(grp, on="ë©´ì êµ¬ê°„", how="left")
                t3["í¸ì°¨(%)"] = (
                    (t3["ì›”ì„¸ê¸ˆ(ë§Œì›)"] - t3["ë¡œì»¬í‰ê· ì›”ì„¸"]) /
                    t3["ë¡œì»¬í‰ê· ì›”ì„¸"] * 100
                )

                cutoff = st.slider(
                    "ë¡œì»¬ í‰ê·  ëŒ€ë¹„ ëª‡ % ì´ìƒì„ ê³ ê°€ë¡œ ë³¼ê¹Œìš”?",
                    min_value=10, max_value=80, value=30, step=5
                )

                anomalies_t3 = t3[t3["í¸ì°¨(%)"] >= cutoff].copy()
                anomalies_t3 = anomalies_t3.sort_values("í¸ì°¨(%)", ascending=False)

                c1, c2 = st.columns(2)
                with c1:
                    st.metric("ë¹„êµ ëŒ€ìƒ ê±°ë˜ ìˆ˜", f"{len(t3):,} ê±´")
                with c2:
                    st.metric(
                        f"ë¡œì»¬ í‰ê·  ëŒ€ë¹„ {cutoff}% ì´ìƒ ê³ ê°€ ê±°ë˜ ìˆ˜",
                        f"{len(anomalies_t3):,} ê±´"
                    )

                st.write("#### ğŸ“‹ ê³ ê°€ ê±°ë˜ ë¦¬ìŠ¤íŠ¸ (ë¡œì»¬ í‰ê·  ëŒ€ë¹„)")
                show_cols3 = [
                    "ì£¼íƒìœ í˜•",
                    "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in anomalies_t3.columns else "ê±´ë¬¼ëª…",
                    "ì „ìš©ë©´ì (ã¡)", "ë©´ì êµ¬ê°„",
                    "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë¡œì»¬í‰ê· ì›”ì„¸", "í¸ì°¨(%)",
                    "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”"
                ]
                show_cols3 = [c for c in show_cols3 if c in anomalies_t3.columns]
                st.dataframe(anomalies_t3[show_cols3])

                st.download_button(
                    "ì´ìƒ ê±°ë˜(ë¡œì»¬ ê³ ê°€) CSV ë‹¤ìš´ë¡œë“œ",
                    anomalies_t3.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_ì´ìƒê±°ë˜_ë¡œì»¬ê³ ê°€.csv"
                )

        # â‘£ IQR & Q-Q ê¸°ë°˜ ì´ìƒì¹˜ (êµê³¼ì„œ ìŠ¤íƒ€ì¼)
        with tab4:
            st.subheader(f"â‘£ í†µê³„ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ (IQR ë£° & Q-Q Plot) â€“ {loc_label}")

            data = rent_base["ì›”ì„¸ê¸ˆ(ë§Œì›)"].dropna().copy()

            if len(data) < MIN_RENT_FOR_DIST:
                st.info(
                    f"í†µê³„ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ë¥¼ í•˜ê¸°ì—ëŠ” ë°ì´í„°ê°€ ì¡°ê¸ˆ ì ìŠµë‹ˆë‹¤.  "
                    f"(ì›”ì„¸ {MIN_RENT_FOR_DIST}ê±´ ì´ìƒ ê¶Œì¥, í˜„ì¬ {len(data)}ê±´)"
                )
            else:
                # --- IQR Rule ---
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR

                iqr_mask = (rent_base["ì›”ì„¸ê¸ˆ(ë§Œì›)"] < lower_bound) | (rent_base["ì›”ì„¸ê¸ˆ(ë§Œì›)"] > upper_bound)
                iqr_outliers = rent_base[iqr_mask].copy()

                # --- Q-Q ê¸°ë°˜ ì´ìƒì¹˜ (ì§ì„ ì—ì„œ ë§ì´ ë²—ì–´ë‚œ ì ) ---
                sorted_data = data.sort_values()
                (theoretical_q, ordered_vals), (slope, intercept, r) = stats.probplot(
                    sorted_data, dist="norm", fit=True
                )
                expected = slope * theoretical_q + intercept
                residuals = np.abs(ordered_vals - expected)

                # ì„ê³„ê°’ ì¡°ì ˆ ìŠ¬ë¼ì´ë” (í‘œì¤€í¸ì°¨ ë°°ìˆ˜)
                qq_std_mult = st.slider(
                    "Q-Q ì´ìƒì¹˜ ê¸°ì¤€ (í‘œì¤€í¸ì°¨ ë°°ìˆ˜)",
                    min_value=1.0, max_value=3.0, value=2.0, step=0.1
                )
                thr_qq = qq_std_mult * residuals.std()

                qq_mask = residuals > thr_qq
                qq_outlier_indices = sorted_data.index[qq_mask]
                qq_outliers = rent_base.loc[qq_outlier_indices].copy()

                c1, c2, c3 = st.columns(3)
                with c1:
                    st.metric("ì „ì²´ ì›”ì„¸ ê±°ë˜ ìˆ˜", f"{len(data):,} ê±´")
                with c2:
                    st.metric("IQR ë£° ì´ìƒì¹˜ ìˆ˜", f"{len(iqr_outliers):,} ê±´")
                with c3:
                    st.metric("Q-Q Plot ì´ìƒì¹˜ ìˆ˜", f"{len(qq_outliers):,} ê±´")

                st.write("#### IQR ê¸°ì¤€ ì´ìƒì¹˜ ë¦¬ìŠ¤íŠ¸")
                show_cols_iqr = [
                    "ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in iqr_outliers.columns else "ê±´ë¬¼ëª…",
                    "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”"
                ]
                show_cols_iqr = [c for c in show_cols_iqr if c in iqr_outliers.columns]
                st.dataframe(iqr_outliers[show_cols_iqr])

                st.download_button(
                    "IQR ê¸°ì¤€ ì´ìƒì¹˜ CSV ë‹¤ìš´ë¡œë“œ",
                    iqr_outliers.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_ì´ìƒì¹˜_IQR.csv"
                )

                st.write("#### Q-Q Plot ê¸°ì¤€ ì´ìƒì¹˜ ë¦¬ìŠ¤íŠ¸")
                show_cols_qq = [
                    "ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                    "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in qq_outliers.columns else "ê±´ë¬¼ëª…",
                    "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ì¸µ", "ê±´ì¶•ë…„ë„", "ê³„ì•½ë…„ì›”"
                ]
                show_cols_qq = [c for c in show_cols_qq if c in qq_outliers.columns]
                st.dataframe(qq_outliers[show_cols_qq])

                st.download_button(
                    "Q-Q Plot ê¸°ì¤€ ì´ìƒì¹˜ CSV ë‹¤ìš´ë¡œë“œ",
                    qq_outliers.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_ì´ìƒì¹˜_QQ.csv"
                )

                # Q-Q Plot ì‹œê°í™” (êµê³¼ì„œ ì—°ê²°ìš©)
                fig, ax = plt.subplots()
                ax.scatter(theoretical_q, ordered_vals, alpha=0.7, label="Observed rents")
                ax.plot(theoretical_q, expected, color="red", linewidth=2, label="Reference line")
                ax.set_title(f"Q-Q Plot of Monthly Rent ({loc_label})")
                ax.set_xlabel("Theoretical quantiles")
                ax.set_ylabel("Observed monthly rent (10k KRW)")
                ax.legend(loc="best")
                st.pyplot(fig)


# =========================
# 7. í˜ì´ì§€ 4: ìš”ì¸ ë¶„ì„
# =========================
elif page == "ìš”ì¸ ë¶„ì„":
    st.header("ğŸ“Š ìš”ì¸ë³„ ì„ëŒ€ë£Œ ì˜í–¥ ë¶„ì„ (ìˆ˜ì—… ê¸°ë°˜, ì›”ì„¸ ê¸°ì¤€)")

    scope = st.radio(
        "ë¶„ì„ ë²”ìœ„ ì„ íƒ",
        ["í˜„ì¬ ì„ íƒëœ êµ¬/ë™ ê¸°ì¤€", "ì„œìš¸ ì „ì²´ ê¸°ì¤€"],
        index=0,
        horizontal=True
    )

    if scope == "ì„œìš¸ ì „ì²´ ê¸°ì¤€":
        base = apply_common_filters(df, gu=None, dong="ì „ì²´")
        scope_loc_label = get_loc_label(None, "ì „ì²´", selected_housing)
    else:
        base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)
        scope_loc_label = loc_label

    st.caption(f"""
â€» ë¶„ì„ ë²”ìœ„: **{scope_loc_label}** ê¸°ì¤€ì…ë‹ˆë‹¤.  
â€» í•„í„°(ë©´ì , ê±´ì¶•ë…„ë„, ê°±ì‹  ì—¬ë¶€ ë“±)ê°€ ëª¨ë‘ ì ìš©ëœ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  
â€» ì „ì„¸ëŠ” ì´ë¯¸ ì œê±°ë˜ì–´ **ì›”ì„¸ ê¸ˆì•¡ ê¸°ì¤€**ìœ¼ë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.
""")

    rent_all = get_rent_only(base).copy()

    if len(rent_all) < MIN_RENT_FOR_BASIC:
        st.info(
            f"í˜„ì¬ ì„ íƒ ë²”ìœ„ì—ì„œ ì›”ì„¸ ê±°ë˜ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. "
            f"(ì›”ì„¸ {MIN_RENT_FOR_BASIC}ê±´ ë¯¸ë§Œ)\n"
            "í•„í„°ë¥¼ ì™„í™”í•˜ê±°ë‚˜ ë²”ìœ„ë¥¼ ë„“í˜€ ë³´ì„¸ìš”."
        )
        st.stop()

    tab_dist, tab_loglog, tab_subway, tab_hedonic = st.tabs([
        "â‘  ì›”ì„¸ ë¶„í¬ & Re-expression",
        "â‘¡ ë³´ì¦ê¸ˆâ€“ì›”ì„¸ ê´€ê³„ (log-log)",
        "â‘¢ ì—­ ì ‘ê·¼ì„± ì§€ìˆ˜ì— ë”°ë¥¸ ë¹„êµ",
        "â‘£ Hedonic ê°€ê²© ëª¨í˜• (ë‹¤ì¤‘íšŒê·€)"
    ])

    # â‘  ë¶„í¬
    with tab_dist:
        st.subheader(f"â‘  ì›”ì„¸ ë¶„í¬ ë¶„ì„ & Re-expression (log ë³€í™˜) â€“ {scope_loc_label}")

        rent = rent_all["ì›”ì„¸ê¸ˆ(ë§Œì›)"].dropna()

        if len(rent) < MIN_RENT_FOR_DIST:
            st.info(
                f"ì›”ì„¸ ë¶„í¬ ë¶„ì„ì„ í•˜ê¸°ì—ëŠ” ë°ì´í„°ê°€ ì¡°ê¸ˆ ì ìŠµë‹ˆë‹¤. "
                f"(ì›”ì„¸ {MIN_RENT_FOR_DIST}ê±´ ì´ìƒ ê¶Œì¥, í˜„ì¬ {len(rent)}ê±´)"
            )
        else:
            log_rent = np.log1p(rent)

            c1, c2 = st.columns(2)
            with c1:
                fig1, ax1 = plt.subplots()
                ax1.hist(rent, bins=30)
                ax1.set_title(f"Raw Monthly Rent Histogram ({scope_loc_label})")
                ax1.set_xlabel("Monthly Rent (10k KRW)")
                ax1.set_ylabel("Count")
                st.pyplot(fig1)

            with c2:
                fig2, ax2 = plt.subplots()
                ax2.hist(log_rent, bins=30)
                ax2.set_title(f"log(1+Rent) Histogram ({scope_loc_label})")
                ax2.set_xlabel("log(1 + Monthly Rent)")
                ax2.set_ylabel("Count")
                st.pyplot(fig2)

            c3, c4 = st.columns(2)
            with c3:
                fig3, ax3 = plt.subplots()
                (th_q1, ord1), (s1, i1, r1) = stats.probplot(rent, dist="norm", fit=True)
                ax3.scatter(th_q1, ord1, alpha=0.7, label="Observed rents")
                ax3.plot(th_q1, s1 * th_q1 + i1, color="red", linewidth=2,
                         label="Reference line (normal fit)")
                ax3.set_title(f"Q-Q Plot (Raw Rent) â€“ {scope_loc_label}")
                ax3.set_xlabel("Theoretical quantiles")
                ax3.set_ylabel("Observed")
                ax3.legend(loc="best")
                st.pyplot(fig3)

            with c4:
                fig4, ax4 = plt.subplots()
                (th_q2, ord2), (s2, i2, r2) = stats.probplot(log_rent, dist="norm", fit=True)
                ax4.scatter(th_q2, ord2, alpha=0.7, label="Observed log-rents")
                ax4.plot(th_q2, s2 * th_q2 + i2, color="red", linewidth=2,
                         label="Reference line (normal fit)")
                ax4.set_title(f"Q-Q Plot (log(1+Rent)) â€“ {scope_loc_label}")
                ax4.set_xlabel("Theoretical quantiles")
                ax4.set_ylabel("Observed")
                ax4.legend(loc="best")
                st.pyplot(fig4)

            st.write("#### Skewness ë¹„êµ (ëŒ€ì¹­ì„± í™•ì¸)")
            skew_df = pd.DataFrame({
                "ë³€ìˆ˜": ["Raw ì›”ì„¸", "log(1+ì›”ì„¸)"],
                "Skewness": [rent.skew(), log_rent.skew()]
            })
            st.dataframe(skew_df)

    # â‘¡ log-log ë³´ì¦ê¸ˆ vs ì›”ì„¸
    with tab_loglog:
        st.subheader(f"â‘¡ ë³´ì¦ê¸ˆâ€“ì›”ì„¸ ê´€ê³„ì˜ ë‹¨ìˆœí™” (log-log Re-expression) â€“ {scope_loc_label}")

        rent_data = rent_all[(rent_all["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0)].copy()

        if len(rent_data) < MIN_RENT_FOR_DIST:
            st.info(
                f"ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ê°€ ëª¨ë‘ ìˆëŠ” ì›”ì„¸ ê±°ë˜ê°€ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤. "
                f"(ìµœì†Œ {MIN_RENT_FOR_DIST}ê±´ ê¶Œì¥, í˜„ì¬ {len(rent_data)}ê±´)"
            )
        else:
            rent_data["log_ë³´ì¦ê¸ˆ"] = np.log1p(rent_data["ë³´ì¦ê¸ˆ(ë§Œì›)"])
            rent_data["log_ì›”ì„¸"] = np.log1p(rent_data["ì›”ì„¸ê¸ˆ(ë§Œì›)"])

            chart_raw = (
                alt.Chart(rent_data)
                .mark_circle(size=40, opacity=0.5)
                .encode(
                    x=alt.X("ë³´ì¦ê¸ˆ(ë§Œì›):Q", title="ë³´ì¦ê¸ˆ (ë§Œì›)"),
                    y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="ì›”ì„¸ (ë§Œì›)"),
                    tooltip=["ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                             "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in rent_data.columns else "ê±´ë¬¼ëª…",
                             "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]
                )
                .properties(title=f"ë³´ì¦ê¸ˆ vs ì›”ì„¸ (Raw, {scope_loc_label})")
            )
            st.altair_chart(chart_raw, use_container_width=True)

            chart_log = (
                alt.Chart(rent_data)
                .mark_circle(size=40, opacity=0.5)
                .encode(
                    x=alt.X("log_ë³´ì¦ê¸ˆ:Q", title="log(1+ë³´ì¦ê¸ˆ)"),
                    y=alt.Y("log_ì›”ì„¸:Q", title="log(1+ì›”ì„¸)"),
                    tooltip=["ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                             "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in rent_data.columns else "ê±´ë¬¼ëª…",
                             "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"]
                )
                .properties(title=f"log(ë³´ì¦ê¸ˆ) vs log(ì›”ì„¸) (log-log, {scope_loc_label})")
            )
            st.altair_chart(chart_log, use_container_width=True)

            X_ll = rent_data[["log_ë³´ì¦ê¸ˆ"]]
            y_ll = rent_data["log_ì›”ì„¸"]
            model_ll = LinearRegression()
            model_ll.fit(X_ll, y_ll)

            st.write("#### log-log ì„ í˜• íšŒê·€ ê²°ê³¼")
            st.write(f"log(ì›”ì„¸) = {model_ll.intercept_:.3f} + {model_ll.coef_[0]:.3f} Ã— log(ë³´ì¦ê¸ˆ)")
            st.caption("â€» Ch.5ì—ì„œ ë‹¤ë£¬ Re-expressionì„ ì‹¤ì œ ë³´ì¦ê¸ˆâ€“ì›”ì„¸ ê´€ê³„ì— ì ìš©í•œ ì˜ˆì‹œ.")

    # â‘¢ ì—­ ì ‘ê·¼ì„± ì§€ìˆ˜ ë¹„êµ
    with tab_subway:
        st.subheader(f"â‘¢ ì—­ ì ‘ê·¼ì„± ì§€ìˆ˜ì— ë”°ë¥¸ ì›”ì„¸ ë¶„í¬ ë¹„êµ â€“ {scope_loc_label}")

        if "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜" not in rent_all.columns:
            st.warning("í˜„ì¬ ë°ì´í„°ì—ëŠ” 'ì—­ì ‘ê·¼ì„±ì§€ìˆ˜' ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            rent = rent_all[~rent_all["ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"].isna()].copy()
            if len(rent) < MIN_RENT_FOR_DIST:
                st.info(
                    f"ì›”ì„¸+ì—­ì ‘ê·¼ì„±ì§€ìˆ˜ ë°ì´í„°ê°€ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤. "
                    f"(ìµœì†Œ {MIN_RENT_FOR_DIST}ê±´ ê¶Œì¥, í˜„ì¬ {len(rent)}ê±´)"
                )
            else:
                median_access = rent["ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"].median()
                rent["ì—­ì ‘ê·¼_ê·¸ë£¹"] = np.where(
                    rent["ì—­ì ‘ê·¼ì„±ì§€ìˆ˜"] >= median_access,
                    "ì—­ ì ‘ê·¼ì„± ìƒìœ„ 50%",
                    "ì—­ ì ‘ê·¼ì„± í•˜ìœ„ 50%"
                )

                w1 = rent[rent["ì—­ì ‘ê·¼_ê·¸ë£¹"] == "ì—­ ì ‘ê·¼ì„± ìƒìœ„ 50%"]["ì›”ì„¸ê¸ˆ(ë§Œì›)"].dropna()
                w0 = rent[rent["ì—­ì ‘ê·¼_ê·¸ë£¹"] == "ì—­ ì ‘ê·¼ì„± í•˜ìœ„ 50%"]["ì›”ì„¸ê¸ˆ(ë§Œì›)"].dropna()

                if len(w1) < MIN_RENT_FOR_BASIC or len(w0) < MIN_RENT_FOR_BASIC:
                    st.info(
                        "ê° ê·¸ë£¹ì˜ í‘œë³¸ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. "
                        f"(ê° ê·¸ë£¹ ìµœì†Œ {MIN_RENT_FOR_BASIC}ê±´ ê¶Œì¥)"
                    )
                else:
                    summary = pd.DataFrame({
                        "ì—­ ì ‘ê·¼ì„± ìƒìœ„ 50%": [
                            w1.median(), w1.quantile(.25), w1.quantile(.75),
                            w1.quantile(.75) - w1.quantile(.25), w1.skew()
                        ],
                        "ì—­ ì ‘ê·¼ì„± í•˜ìœ„ 50%": [
                            w0.median(), w0.quantile(.25), w0.quantile(.75),
                            w0.quantile(.75) - w0.quantile(.25), w0.skew()
                        ]
                    }, index=["median", "HL", "HU", "spread(HU-HL)", "skew(H)"])

                    st.write("#### Numerical Summary (Hinges & Skewness)")
                    st.dataframe(summary)

                    melt_df = rent[["ì›”ì„¸ê¸ˆ(ë§Œì›)", "ì—­ì ‘ê·¼_ê·¸ë£¹"]].copy()
                    fig, ax = plt.subplots()
                    melt_df.boxplot(by="ì—­ì ‘ê·¼_ê·¸ë£¹", column="ì›”ì„¸ê¸ˆ(ë§Œì›)", ax=ax)
                    ax.set_title(f"ì—­ ì ‘ê·¼ì„± ìƒ/í•˜ìœ„ ê·¸ë£¹ë³„ ì›”ì„¸ Boxplot ({scope_loc_label})")
                    ax.set_ylabel("ì›”ì„¸ (ë§Œì›)")
                    plt.suptitle("")
                    st.pyplot(fig)

                    st.caption("â€» Ch.4,5ì˜ ë¶„í¬/ëŒ€ì¹­ì„± ê°œë…ê³¼ ì—°ê²°í•´ì„œ ì—­ì„¸ê¶Œ í”„ë¦¬ë¯¸ì—„ì„ í•´ì„ ê°€ëŠ¥.")

    # â‘£ Hedonic ëª¨í˜•
    with tab_hedonic:
        st.subheader(f"â‘£ Hedonic ê°€ê²© ê²°ì • ëª¨í˜• (ë‹¤ì¤‘íšŒê·€, ì›”ì„¸ ì¢…ì†ë³€ìˆ˜) â€“ {scope_loc_label}")

        rent = rent_all.copy()

        if len(rent) < MIN_RENT_FOR_HEDONIC:
            st.info(
                "Hedonic ëª¨í˜•ì„ ì¶”ì •í•˜ê¸°ì— ì›”ì„¸ ê±°ë˜ í‘œë³¸ì´ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤.  \n"
                f"(ìµœì†Œ {MIN_RENT_FOR_HEDONIC}ê±´ ê¶Œì¥, í˜„ì¬ {len(rent)}ê±´)"
            )
        else:
            # 1) í›„ë³´ ì„¤ëª…ë³€ìˆ˜ ëª©ë¡
            candidate_cols = []
            for col in ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ì „ìš©ë©´ì (ã¡)", "ê±´ì¶•ë…„ë„", "ì¸µ"]:
                if col in rent.columns:
                    candidate_cols.append(col)
            if "ì—­ì ‘ê·¼ì„±ì§€ìˆ˜" in rent.columns:
                candidate_cols.append("ì—­ì ‘ê·¼ì„±ì§€ìˆ˜")

            if not candidate_cols:
                st.warning("íšŒê·€ ë¶„ì„ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜í˜• ì„¤ëª… ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # 2) ê²°ì¸¡ ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ì€ ë³€ìˆ˜ëŠ” ìë™ ì œì™¸
                non_missing_ratio = {
                    col: rent[col].notna().sum() / len(rent) for col in candidate_cols
                }
                feature_cols = [
                    col for col in candidate_cols
                    if non_missing_ratio[col] >= MIN_NONMISSING_RATIO
                ]

                if len(feature_cols) < 2:
                    st.warning(
                        "ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ ë‚®ì€ ì„¤ëª…ë³€ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.  \n"
                        "ê±´ì¶•ë…„ë„/ì¸µ ë“±ì˜ í•„í„°ë¥¼ ì™„í™”í•˜ê±°ë‚˜, MIN_NONMISSING_RATIOë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”."
                    )
                else:
                    reg_df = rent[feature_cols + ["ì›”ì„¸ê¸ˆ(ë§Œì›)"]].dropna().copy()
                    if len(reg_df) < MIN_RENT_FOR_HEDONIC:
                        st.info(
                            "ê²°ì¸¡ì¹˜ ì œê±° í›„ Hedonic ëª¨í˜•ì— ì‚¬ìš©í•  í‘œë³¸ì´ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤.  \n"
                            f"(ìµœì†Œ {MIN_RENT_FOR_HEDONIC}ê±´ ê¶Œì¥, í˜„ì¬ {len(reg_df)}ê±´)"
                        )
                    else:
                        X = reg_df[feature_cols]
                        y = reg_df["ì›”ì„¸ê¸ˆ(ë§Œì›)"]

                        model = LinearRegression()
                        model.fit(X, y)
                        r2 = model.score(X, y)

                        coef_df = pd.DataFrame({
                            "ë³€ìˆ˜": feature_cols,
                            "ê³„ìˆ˜(Î²)": model.coef_
                        })
                        coef_df["|Î²|"] = coef_df["ê³„ìˆ˜(Î²)"].abs()
                        coef_df = coef_df.sort_values("|Î²|", ascending=False)

                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("íšŒê·€ì— ì‚¬ìš©ëœ í‘œë³¸ ìˆ˜", f"{len(reg_df):,} ê±´")
                        with col2:
                            st.metric("ê²°ì •ê³„ìˆ˜ (RÂ²)", f"{r2:.3f}")

                        st.write("#### íšŒê·€ ê³„ìˆ˜ (Hedonic ëª¨í˜• ê²°ê³¼)")
                        st.dataframe(coef_df[["ë³€ìˆ˜", "ê³„ìˆ˜(Î²)"]])

                        coef_chart = (
                            alt.Chart(coef_df)
                            .mark_bar()
                            .encode(
                                x=alt.X("ê³„ìˆ˜(Î²):Q", title="íšŒê·€ ê³„ìˆ˜"),
                                y=alt.Y("ë³€ìˆ˜:N", sort='-x', title="ë³€ìˆ˜"),
                                tooltip=["ë³€ìˆ˜", "ê³„ìˆ˜(Î²)"]
                            )
                            .properties(title=f"Hedonic íšŒê·€ ê³„ìˆ˜ Bar Chart ({scope_loc_label})")
                        )
                        st.altair_chart(coef_chart, use_container_width=True)

                        st.write("#### ì‹¤ì œ ì›”ì„¸ vs ì˜ˆì¸¡ ì›”ì„¸ (ëª¨í˜• ì í•©ë„)")
                        y_pred = model.predict(X)
                        fit_df = pd.DataFrame({
                            "ì‹¤ì œê°’": y.values,
                            "ì˜ˆì¸¡ê°’": y_pred
                        })

                        scatter_fit = (
                            alt.Chart(fit_df)
                            .mark_point(size=40, opacity=0.6)
                            .encode(
                                x=alt.X("ì‹¤ì œê°’:Q", title="ì‹¤ì œ ì›”ì„¸ (ë§Œì›)"),
                                y=alt.Y("ì˜ˆì¸¡ê°’:Q", title="ì˜ˆì¸¡ ì›”ì„¸ (ë§Œì›)"),
                                tooltip=["ì‹¤ì œê°’", "ì˜ˆì¸¡ê°’"]
                            )
                        )

                        min_val = float(min(fit_df["ì‹¤ì œê°’"].min(), fit_df["ì˜ˆì¸¡ê°’"].min()))
                        max_val = float(max(fit_df["ì‹¤ì œê°’"].max(), fit_df["ì˜ˆì¸¡ê°’"].max()))
                        line_df = pd.DataFrame({"x": [min_val, max_val], "y": [min_val, max_val]})

                        line = (
                            alt.Chart(line_df)
                            .mark_line()
                            .encode(
                                x="x:Q",
                                y="y:Q"
                            )
                        )

                        st.altair_chart(
                            (scatter_fit + line).properties(
                                title=f"ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (y=x ê¸°ì¤€ì„  í¬í•¨, {scope_loc_label})"
                            ),
                            use_container_width=True
                        )

                        st.caption("""
â€» ì´ ëª¨í˜•ì´ ë°”ë¡œ 'ì¢…í•©ëª¨ë¸ ë‹¤ì¤‘íšŒê·€'ì— í•´ë‹¹.  
   - ì¢…ì†ë³€ìˆ˜: ì›”ì„¸  
   - ì„¤ëª…ë³€ìˆ˜: ë³´ì¦ê¸ˆ, ì „ìš©ë©´ì , ê±´ì¶•ë…„ë„, ì¸µ, ì—­ì ‘ê·¼ì„±ì§€ìˆ˜(ê²°ì¸¡ ì ì€ ë³€ìˆ˜ë§Œ ìë™ ì„ íƒ)  
   - RÂ²ì™€ ê³„ìˆ˜ ë¶€í˜¸/í¬ê¸°ë¥¼ ì´ìš©í•´ ì—­ì„¸ê¶Œ í”„ë¦¬ë¯¸ì—„ê³¼ êµ¬ì¡°ì  ìš”ì¸ì„ í•´ì„í•  ìˆ˜ ìˆìŒ.
""")


# =========================
# 8. í˜ì´ì§€ 5: í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„
# =========================
elif page == "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„":
    st.header(f"ğŸ” í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ â€“ {loc_label} (ì›”ì„¸ ê¸°ì¤€)")

    base = apply_common_filters(df, gu=selected_gu, dong=selected_dong)
    rent_base = get_rent_only(base)

    if len(rent_base) < MIN_RENT_FOR_CLUSTER:
        st.info(
            "í´ëŸ¬ìŠ¤í„°ë§ì„ í•˜ê¸°ì—ëŠ” ì›”ì„¸ ê±°ë˜ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.  \n"
            f"(ìµœì†Œ {MIN_RENT_FOR_CLUSTER}ê±´ ê¶Œì¥, í˜„ì¬ {len(rent_base)}ê±´)"
        )
    else:
        tab_k1, tab_k2 = st.tabs(["ì „ì²´ ì›”ì„¸ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§", "ì´ìƒ ê±°ë˜ ì¤‘ì‹¬ í´ëŸ¬ìŠ¤í„°ë§"])

        # ----------------
        # ë³´ì¡°: ìºì‹œëœ KMeans
        # ----------------
        @st.cache_data(show_spinner=False)
        def run_kmeans(data: pd.DataFrame, k: int):
            scaler = StandardScaler()
            scaled = scaler.fit_transform(data)
            model = KMeans(n_clusters=k, random_state=42, n_init="auto")
            labels = model.fit_predict(scaled)
            return labels

        with tab_k1:
            st.subheader(f"â‘  ì „ì²´ ì›”ì„¸ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§ ({loc_label})")

            use_cols = [
                "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)", "ê±´ì¶•ë…„ë„", "ì¸µ"
            ]
            use_cols = [c for c in use_cols if c in rent_base.columns]

            data_k = rent_base[use_cols].dropna().copy()

            if len(data_k) < MIN_RENT_FOR_CLUSTER:
                st.info(
                    "ìœ íš¨í•œ ì›”ì„¸ ë°ì´í„°(ê²°ì¸¡ê°’ ì œê±° í›„)ê°€ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤.  \n"
                    f"(ìµœì†Œ {MIN_RENT_FOR_CLUSTER}ê±´ ê¶Œì¥, í˜„ì¬ {len(data_k)}ê±´)"
                )
            else:
                k = st.slider("í´ëŸ¬ìŠ¤í„° ìˆ˜ (K)", min_value=2, max_value=8, value=4)

                labels = run_kmeans(data_k, k)
                data_k["cluster"] = labels.astype(int)

                result = data_k.merge(
                    rent_base[["ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                               "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in rent_base.columns else "ê±´ë¬¼ëª…",
                               "ê³„ì•½ë…„ì›”"]],
                    left_index=True,
                    right_index=True,
                    how="left"
                )

                st.write("#### ğŸ“‹ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìƒ˜í”Œ")
                st.dataframe(result.head(50))

                st.download_button(
                    "í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    result.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_í´ëŸ¬ìŠ¤í„°ë§_ì „ì²´ì›”ì„¸.csv"
                )

                st.write("#### ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’")
                summary_k = data_k.groupby("cluster").mean()
                st.dataframe(summary_k)

                if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(data_k.columns):
                    chart_df = data_k.reset_index(drop=True).copy()
                    chart_df["cluster"] = chart_df["cluster"].astype(str)

                    scatter = (
                        alt.Chart(chart_df)
                        .mark_circle(size=60, opacity=0.6)
                        .encode(
                            x=alt.X("ì „ìš©ë©´ì (ã¡):Q", title="ì „ìš©ë©´ì (ã¡)"),
                            y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="ì›”ì„¸(ë§Œì›)"),
                            color="cluster:N",
                            tooltip=["cluster", "ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë³´ì¦ê¸ˆ(ë§Œì›)"]
                        )
                        .properties(title=f"ì „ìš©ë©´ì  vs ì›”ì„¸ (í´ëŸ¬ìŠ¤í„° ìƒ‰, {loc_label})")
                    )
                    st.write("#### ğŸ¨ ì „ìš©ë©´ì  vs ì›”ì„¸ (í´ëŸ¬ìŠ¤í„° ìƒ‰)")
                    st.altair_chart(scatter, use_container_width=True)

        with tab_k2:
            st.subheader(f"â‘¡ ì´ìƒ ê±°ë˜ ì¤‘ì‹¬ í´ëŸ¬ìŠ¤í„°ë§ ({loc_label})")

            df_anom = rent_base.copy()

            df_anom["ë¹„ìœ¨"] = np.where(
                df_anom["ë³´ì¦ê¸ˆ(ë§Œì›)"] > 0,
                df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"] / df_anom["ë³´ì¦ê¸ˆ(ë§Œì›)"],
                np.nan
            )
            thr1 = df_anom["ë¹„ìœ¨"].quantile(0.90)
            df_anom["ì´ìƒ_ë¹„ìœ¨"] = df_anom["ë¹„ìœ¨"] >= thr1

            thr3 = df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"].quantile(0.90)
            df_anom["ì´ìƒ_ê³ ê°€"] = df_anom["ì›”ì„¸ê¸ˆ(ë§Œì›)"] >= thr3

            df_anom["ì´ìƒê±°ë˜"] = df_anom["ì´ìƒ_ë¹„ìœ¨"] | df_anom["ì´ìƒ_ê³ ê°€"]

            anom_only = df_anom[df_anom["ì´ìƒê±°ë˜"]].copy()

            st.write(f"ë°œê²¬ëœ ì´ìƒ ê±°ë˜ ìˆ˜: **{len(anom_only):,} ê±´**")

            if len(anom_only) < MIN_RENT_FOR_CLUSTER:
                st.info(
                    "ì´ìƒ ê±°ë˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ í´ëŸ¬ìŠ¤í„°ë§ì´ ì–´ë µìŠµë‹ˆë‹¤.  \n"
                    f"(ìµœì†Œ {MIN_RENT_FOR_CLUSTER}ê±´ ê¶Œì¥, í˜„ì¬ {len(anom_only)}ê±´)"
                )
            else:
                use_cols2 = [
                    "ì „ìš©ë©´ì (ã¡)", "ë³´ì¦ê¸ˆ(ë§Œì›)", "ì›”ì„¸ê¸ˆ(ë§Œì›)",
                    "ì „ìš©ë©´ì ë‹¹ ì›”ì„¸(ë§Œì›/ã¡)", "ë¹„ìœ¨", "ê±´ì¶•ë…„ë„"
                ]
                use_cols2 = [c for c in use_cols2 if c in anom_only.columns]

                data_k2 = anom_only[use_cols2].dropna().copy()

                if len(data_k2) < MIN_RENT_FOR_CLUSTER:
                    st.info(
                        "ìœ íš¨í•œ ì´ìƒ ê±°ë˜ ë°ì´í„°ê°€ ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤.  \n"
                        f"(ìµœì†Œ {MIN_RENT_FOR_CLUSTER}ê±´ ê¶Œì¥, í˜„ì¬ {len(data_k2)}ê±´)"
                    )
                else:
                    k2 = st.slider("í´ëŸ¬ìŠ¤í„° ìˆ˜ (K)", min_value=2, max_value=8,
                                   value=3, key="anom_k")

                    labels2 = run_kmeans(data_k2, k2)
                    data_k2["cluster"] = labels2.astype(int)

                    result2 = data_k2.merge(
                        anom_only[["ì£¼íƒìœ í˜•", "êµ¬", "ë™",
                                   "ë‹¨ì§€ëª…" if "ë‹¨ì§€ëª…" in anom_only.columns else "ê±´ë¬¼ëª…",
                                   "ê³„ì•½ë…„ì›”"]],
                        left_index=True,
                        right_index=True,
                        how="left"
                    )

                    st.write("#### ğŸ“‹ ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìƒ˜í”Œ")
                    st.dataframe(result2.head(50))

                    st.download_button(
                        "ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                        result2.to_csv(index=False).encode("utf-8-sig"),
                        file_name=f"{selected_housing}_{selected_gu}_{selected_dong}_í´ëŸ¬ìŠ¤í„°ë§_ì´ìƒê±°ë˜.csv"
                    )

                    st.write("#### ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’")
                    summary_k2 = data_k2.groupby("cluster").mean()
                    st.dataframe(summary_k2)

                    if {"ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)"}.issubset(data_k2.columns):
                        chart2 = data_k2.reset_index(drop=True).copy()
                        chart2["cluster"] = chart2["cluster"].astype(str)

                        scatter2 = (
                            alt.Chart(chart2)
                            .mark_circle(size=60, opacity=0.6)
                            .encode(
                                x=alt.X("ì „ìš©ë©´ì (ã¡):Q", title="ì „ìš©ë©´ì (ã¡)"),
                                y=alt.Y("ì›”ì„¸ê¸ˆ(ë§Œì›):Q", title="ì›”ì„¸(ë§Œì›)"),
                                color="cluster:N",
                                tooltip=["cluster", "ì „ìš©ë©´ì (ã¡)", "ì›”ì„¸ê¸ˆ(ë§Œì›)", "ë³´ì¦ê¸ˆ(ë§Œì›)"]
                            )
                            .properties(title=f"ì „ìš©ë©´ì  vs ì›”ì„¸ (ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°, {loc_label})")
                        )
                        st.write("#### ğŸ¨ ì „ìš©ë©´ì  vs ì›”ì„¸ (ì´ìƒ ê±°ë˜ í´ëŸ¬ìŠ¤í„°)")
                        st.altair_chart(scatter2, use_container_width=True)


# =========================
# 9. í˜ì´ì§€ 6: AI ì •ì„± ë¶„ì„ (CrewAI)
# =========================
elif page == "AI ì •ì„± ë¶„ì„":
    st.header(f"ğŸ§  AI ì •ì„± ë¶„ì„ (CrewAI ê¸°ë°˜) â€“ {loc_label}")

    # ì „ì²´(ì„œìš¸ ì „ì²´) + í˜„ì¬ ì¡°ê±´ ë°ì´í„° (ë‘˜ ë‹¤ ì›”ì„¸ only)
    df_all_ai = get_rent_only(apply_common_filters(df, gu=None, dong="ì „ì²´"))
    df_filtered_ai = get_rent_only(apply_common_filters(df, gu=selected_gu, dong=selected_dong))

    if df_all_ai.empty:
        st.info("ì „ì²´ ì›”ì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì›ì‹œ CSVë‚˜ ì „ì²˜ë¦¬ë¥¼ ë¨¼ì € í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    user_condition_text = build_user_condition_text(
        housing_type=selected_housing,
        gu=selected_gu,
        dong=selected_dong,
        area_range=area_range,
        year_range=year_range,
        only_renew=only_renew,
    )

    tab_rec, tab_coach, tab_comp, tab_rarity = st.tabs(
        ["AI ë§¤ë¬¼ ì¶”ì²œ", "AI ì¡°ê±´ ì½”ì¹˜", "AI ì§€ì—­/ìœ í˜• ë¹„êµ", "ì‹œì¥ í¬ì†Œì„± ë¸Œë¦¬í•‘"]
    )

    # ----------------------
    # 9-1. AI ë§¤ë¬¼ ì¶”ì²œ
    # ----------------------
    with tab_rec:
        st.markdown("### ğŸ¯ AI ë§¤ë¬¼ ì¶”ì²œ ë¦¬í¬íŠ¸")
        st.caption("í˜„ì¬ ì‚¬ì´ë“œë°” ì¡°ê±´ê³¼ ìœ„ì¹˜(êµ¬/ë™)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¤ë¬¼ í›„ë³´ë¥¼ ê³ ë¥´ê³ , CrewAIê°€ ì •ì„± ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.")

        cond_text_edit = st.text_area(
            "í˜„ì¬ ì¡°ê±´ ìš”ì•½ (í•„ìš”í•˜ë©´ ìˆ˜ì • ê°€ëŠ¥)",
            value=user_condition_text,
            height=150,
            key="recommend_condition_text",
        )

        extra_inst = st.text_input(
            "ì—ì´ì „íŠ¸ì—ê²Œ ì¶”ê°€ë¡œ ë¶€íƒí•  ë‚´ìš© (ì„ íƒ)",
            value="ë°œí‘œìš©ìœ¼ë¡œ ì“°ê¸° ì¢‹ê²Œ, ë„ˆë¬´ ê³¼ì¥í•˜ì§€ ë§ê³  ì •ë¦¬í•´ì¤˜.",
            key="recommend_extra",
        )

        if st.button("CrewAIë¡œ ë§¤ë¬¼ ì¶”ì²œ ë¦¬í¬íŠ¸ ìƒì„±"):
            if df_filtered_ai.empty:
                st.warning("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤. êµ¬/ë™ì´ë‚˜ ì„¸ë¶€ í•„í„°ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
            else:
                candidates_text = build_candidates_text(df_filtered_ai)

                with st.spinner("CrewAIê°€ ë§¤ë¬¼ ì¶”ì²œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = run_recommendation_report(
                        user_condition_text=cond_text_edit,
                        candidates_text=candidates_text,
                        extra_instruction=extra_inst,
                    )

                st.markdown("#### ê²°ê³¼ ë¦¬í¬íŠ¸")
                st.markdown(report)
                st.session_state["last_recommend_report"] = report

    # ----------------------
    # 9-2. AI ì¡°ê±´ ì½”ì¹˜
    # ----------------------
    with tab_coach:
        st.markdown("### ğŸ§­ AI ì¡°ê±´ ì½”ì¹˜ ë¦¬í¬íŠ¸")
        st.caption("í˜„ì¬ ì¡°ê±´ì´ ë„ˆë¬´ ë¹¡ì„¸ë©´, ì–´ë–¤ ì‹ìœ¼ë¡œ ì¡°ê±´ì„ ì™„í™”í•˜ë©´ ë§¤ë¬¼ì´ ìƒê¸°ëŠ”ì§€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ì–´ì„œ ì„¤ëª…í•©ë‹ˆë‹¤.")

        cond_text_edit2 = st.text_area(
            "í˜„ì¬ ì¡°ê±´ ìš”ì•½ (í•„ìš”í•˜ë©´ ìˆ˜ì • ê°€ëŠ¥)",
            value=user_condition_text,
            height=150,
            key="coach_condition_text",
        )

        extra_inst2 = st.text_input(
            "ì—ì´ì „íŠ¸ì—ê²Œ ì¶”ê°€ë¡œ ë¶€íƒí•  ë‚´ìš© (ì„ íƒ)",
            value="í•™ìƒê³¼ ì‚¬íšŒì´ˆë…„ìƒ ê´€ì ì—ì„œ ì¡°ì–¸ì„ ì¶”ê°€í•´ì¤˜.",
            key="coach_extra",
        )

        if st.button("CrewAIë¡œ ì¡°ê±´ ì½”ì¹­ ë¦¬í¬íŠ¸ ìƒì„±"):
            scenarios = []
            type_tuple = tuple(sorted(selected_type)) if selected_type else tuple()

            # ì‹œë‚˜ë¦¬ì˜¤ 1: ê°™ì€ êµ¬ì—ì„œ ë™ì„ 'ì „ì²´'ë¡œ í™•ì¥
            if selected_gu is not None:
                df_s1 = apply_common_filters_cached(
                    df,
                    selected_housing,
                    selected_gu,
                    "ì „ì²´",
                    type_tuple,
                    area_range,
                    year_range,
                    only_renew,
                )
                df_s1 = get_rent_only(df_s1)
                scenarios.append(
                    {
                        "name": "ë™ ë²”ìœ„ë¥¼ ì „ì²´ë¡œ í™•ì¥",
                        "description": f"í˜„ì¬ êµ¬({selected_gu})ì—ì„œ ë™ ì¡°ê±´ì„ '{selected_dong}' â†’ 'ì „ì²´'ë¡œ ì™„í™”",
                        "count": len(df_s1),
                        "examples_df": df_s1,
                    }
                )

            # ì‹œë‚˜ë¦¬ì˜¤ 2: ì „ìš©ë©´ì  ë²”ìœ„ Â±5ã¡ ì™„í™”
            if area_range is not None and "ì „ìš©ë©´ì (ã¡)" in df.columns:
                global_min_area = float(df["ì „ìš©ë©´ì (ã¡)"].min())
                global_max_area = float(df["ì „ìš©ë©´ì (ã¡)"].max())
                new_min = max(global_min_area, area_range[0] - 5)
                new_max = min(global_max_area, area_range[1] + 5)
                new_area_range = (new_min, new_max)

                df_s2 = apply_common_filters_cached(
                    df,
                    selected_housing,
                    selected_gu,
                    selected_dong,
                    type_tuple,
                    new_area_range,
                    year_range,
                    only_renew,
                )
                df_s2 = get_rent_only(df_s2)
                scenarios.append(
                    {
                        "name": "ì „ìš©ë©´ì  ë²”ìœ„ Â±5ã¡ ì™„í™”",
                        "description": f"ì „ìš©ë©´ì  ë²”ìœ„ë¥¼ {area_range[0]:.1f}~{area_range[1]:.1f}ã¡ â†’ {new_min:.1f}~{new_max:.1f}ã¡ë¡œ ì™„í™”",
                        "count": len(df_s2),
                        "examples_df": df_s2,
                    }
                )

            # ì‹œë‚˜ë¦¬ì˜¤ 3: ê±´ì¶•ë…„ë„ ë²”ìœ„ 5ë…„ í™•ì¥
            if year_range is not None and "ê±´ì¶•ë…„ë„" in df.columns:
                global_min_year = int(df["ê±´ì¶•ë…„ë„"].min())
                global_max_year = int(df["ê±´ì¶•ë…„ë„"].max())
                new_ymin = max(global_min_year, year_range[0] - 5)
                new_ymax = min(global_max_year, year_range[1] + 5)
                new_year_range = (new_ymin, new_ymax)

                df_s3 = apply_common_filters_cached(
                    df,
                    selected_housing,
                    selected_gu,
                    selected_dong,
                    type_tuple,
                    area_range,
                    new_year_range,
                    only_renew,
                )
                df_s3 = get_rent_only(df_s3)
                scenarios.append(
                    {
                        "name": "ê±´ì¶•ë…„ë„ ë²”ìœ„ 5ë…„ í™•ì¥",
                        "description": f"ê±´ì¶•ë…„ë„ ë²”ìœ„ë¥¼ {year_range[0]}~{year_range[1]}ë…„ â†’ {new_ymin}~{new_ymax}ë…„ìœ¼ë¡œ ì™„í™”",
                        "count": len(df_s3),
                        "examples_df": df_s3,
                    }
                )

            # ì‹œë‚˜ë¦¬ì˜¤ 4: ê°±ì‹  ê³„ì•½ ì¡°ê±´ í•´ì œ (only_renewê°€ Trueì¼ ë•Œ ì˜ë¯¸ ìˆìŒ)
            if only_renew:
                df_s4 = apply_common_filters_cached(
                    df,
                    selected_housing,
                    selected_gu,
                    selected_dong,
                    type_tuple,
                    area_range,
                    year_range,
                    False,  # ê°±ì‹ ë§Œ ë³´ê¸° í•´ì œ
                )
                df_s4 = get_rent_only(df_s4)
                scenarios.append(
                    {
                        "name": "ê°±ì‹  ê³„ì•½ ì¡°ê±´ í•´ì œ",
                        "description": "ê³„ì•½êµ¬ë¶„ì´ 'ê°±ì‹ 'ì¸ ê±°ë˜ë§Œ ë³´ë˜ ì¡°ê±´ì„ í•´ì œí•˜ì—¬ ëª¨ë“  ê³„ì•½êµ¬ë¶„ í¬í•¨",
                        "count": len(df_s4),
                        "examples_df": df_s4,
                    }
                )

            if not scenarios:
                st.warning("ì¡°ê±´ ì™„í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì„¸ë¶€ í•„í„°ë¥¼ ë¨¼ì € ì§€ì •í•´ ì£¼ì„¸ìš”.")
            else:
                scenario_text = build_condition_scenario_text(scenarios)

                with st.spinner("CrewAIê°€ ì¡°ê±´ ì½”ì¹­ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = run_condition_coach_report(
                        user_condition_text=cond_text_edit2,
                        scenario_text=scenario_text,
                        extra_instruction=extra_inst2,
                    )

                st.markdown("#### ê²°ê³¼ ë¦¬í¬íŠ¸")
                st.markdown(report)
                st.session_state["last_coach_report"] = report

    # ----------------------
    # 9-3. AI ì§€ì—­/ìœ í˜• ë¹„êµ
    # ----------------------
    with tab_comp:
        st.markdown("### âš–ï¸ AI ì§€ì—­/ìœ í˜• ë¹„êµ ë¦¬í¬íŠ¸")
        st.caption("êµ¬Â·ì£¼íƒìœ í˜•ë³„ ìš”ì•½ í†µê³„ë¥¼ ì •ë¦¬í•´ì„œ, ì–´ë–¤ ì§€ì—­/ìœ í˜•ì´ ì–´ë–¤ ê´€ì ì—ì„œ ìœ ë¦¬í•œì§€ CrewAIê°€ í’€ì–´ì¤ë‹ˆë‹¤.")

        # ë¹„êµìš© ë°ì´í„°: ì„œìš¸ ì „ì²´ ê¸°ì¤€ìœ¼ë¡œ, í˜„ì¬ ì£¼íƒìœ í˜•/ì„¸ë¶€ í•„í„°ëŠ” ê·¸ëŒ€ë¡œ ì ìš©
        df_comp_base = df_all_ai.copy()  # ì´ë¯¸ apply_common_filters + get_rent_only ëœ ìƒíƒœ

        comp_text_default = build_comparison_text(df_comp_base)
        comp_text_edit = st.text_area(
            "ë¹„êµ ëŒ€ìƒ ìš”ì•½ (ìë™ ìƒì„±, í•„ìš”í•˜ë©´ ìˆ˜ì •)",
            value=comp_text_default,
            height=220,
            key="comp_text",
        )

        extra_inst3 = st.text_input(
            "ì—ì´ì „íŠ¸ì—ê²Œ ì¶”ê°€ë¡œ ë¶€íƒí•  ë‚´ìš© (ì„ íƒ)",
            value="ê´€ì•…êµ¬ì™€ ë™ì‘êµ¬, ì˜¤í”¼ìŠ¤í…”ê³¼ ì—°ë¦½ë‹¤ì„¸ëŒ€ì˜ ì°¨ì´ì— íŠ¹íˆ ì§‘ì¤‘í•´ì„œ ì„¤ëª…í•´ì¤˜.",
            key="comp_extra",
        )

        if st.button("CrewAIë¡œ ì§€ì—­/ìœ í˜• ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"):
            with st.spinner("CrewAIê°€ ë¹„êµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                report = run_comparison_report(
                    comparison_text=comp_text_edit,
                    extra_instruction=extra_inst3,
                )

            st.markdown("#### ê²°ê³¼ ë¦¬í¬íŠ¸")
            st.markdown(report)
            st.session_state["last_comparison_report"] = report

    # ----------------------
    # 9-4. ì‹œì¥ í¬ì†Œì„±/ê²½ìŸë„ ë¸Œë¦¬í•‘
    # ----------------------
    with tab_rarity:
        st.markdown("### ğŸ“ˆ ì‹œì¥ í¬ì†Œì„±/ê²½ìŸë„ ë¸Œë¦¬í•‘")
        st.caption("í˜„ì¬ ì¡°ê±´ìœ¼ë¡œ ë‚˜ì˜¨ ë§¤ë¬¼ì´ ì „ì²´ ì‹œì¥ì—ì„œ ì–¼ë§ˆë‚˜ í¬ì†Œí•œì§€, ê²½ìŸë„ì™€ í˜‘ìƒë ¥ì„ CrewAIê°€ í•´ì„í•©ë‹ˆë‹¤.")

        rarity_text_default = build_market_rarity_text(
            df_all=df_all_ai,
            df_filtered=df_filtered_ai,
            condition_text=user_condition_text,
        )

        rarity_text_edit = st.text_area(
            "ì‹œì¥ í¬ì†Œì„± ìš”ì•½ (ìë™ ìƒì„±, í•„ìš”í•˜ë©´ ìˆ˜ì •)",
            value=rarity_text_default,
            height=250,
            key="rarity_text",
        )

        extra_inst4 = st.text_input(
            "ì—ì´ì „íŠ¸ì—ê²Œ ì¶”ê°€ë¡œ ë¶€íƒí•  ë‚´ìš© (ì„ íƒ)",
            value="ì—°êµ¬/ì •ì±… ì‹œì‚¬ì ì„ 2~3ê°œ ì •ë„ ê¼­ í¬í•¨í•´ì¤˜.",
            key="rarity_extra",
        )

        if st.button("CrewAIë¡œ í¬ì†Œì„± ë¸Œë¦¬í•‘ ìƒì„±"):
            with st.spinner("CrewAIê°€ ë¸Œë¦¬í•‘ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                report = run_market_rarity_report(
                    rarity_text=rarity_text_edit,
                    extra_instruction=extra_inst4,
                )

            st.markdown("#### ê²°ê³¼ ë¦¬í¬íŠ¸")
            st.markdown(report)
            st.session_state["last_rarity_report"] = report
